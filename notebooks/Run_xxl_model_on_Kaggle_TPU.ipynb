{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n<a href=\"https://www.kaggle.com/kernels/fork/18483792\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open In Kaggle\"/></a>","metadata":{"id":"YONnGjpAYUdU"}},{"cell_type":"markdown","source":"# Run heptabot `xxl` model on Kaggle TPU\n\nThis notebook lets you to process data with our `xxl` model in Kaggle TPU environment. Kaggle is the only widely available environment that provides access `v3-8` TPU topology required by T5 11B checkpoint. With Kaggle, you can efficiently run our `xxl` model.","metadata":{"id":"dCpdqIxO9XlR"}},{"cell_type":"markdown","source":"As Colab has recently switched to Python 3.7 and our dependency `spaCy 1.9.0` supports only Python 3.6, we use `mamba` to ensure that we get the right packages in our environment. To get `mamba`, you should execute the following cell (click the '▷' button). Please note that the runtime will restart after that, so don't schedule the rest of the cells to execute just yet.","metadata":{"id":"ZdmtepIzQcnh"}},{"cell_type":"markdown","source":"After your runtime is restarted, execute the following cell to set some environmental variables:\n\n","metadata":{"id":"WILmgslscMTd"}},{"cell_type":"code","source":"import os\n\nmodel_type = \"xxl\"\n# The steps are largely the same between medium and xxl models. \n# However, we keep this, as it is advantageous to run medium model in Google Colab, while xxl – in Kaggle, and these environments have their differences\n\nos.environ[\"MODEL_PLACE\"] = \"tpu\"\nos.environ[\"HPT_MODEL_TYPE\"] = model_type\n\nif model_type == \"xxl\":\n    os.environ[\"CHECKPOINT_STEP\"] = \"1014000\"\n    os.environ[\"TPU_TOPOLOGY\"] = \"v3-8\"\nelse:\n    os.environ[\"CHECKPOINT_STEP\"] = \"1003800\"\n    os.environ[\"TPU_TOPOLOGY\"] = \"v2-8\"","metadata":{"id":"B9eZYBUZVfLx","execution":{"iopub.status.busy":"2021-07-10T15:16:55.478718Z","iopub.execute_input":"2021-07-10T15:16:55.47931Z","iopub.status.idle":"2021-07-10T15:16:55.49151Z","shell.execute_reply.started":"2021-07-10T15:16:55.47922Z","shell.execute_reply":"2021-07-10T15:16:55.490482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prepare environment\n\nNow click the '▷' on this group of cells. The code below will install the environment for `heptabot` and needs around 10 minutes to execute.","metadata":{"id":"fcyITR3j-Q-E"}},{"cell_type":"code","source":"!pip install -qq t5==0.9.0 seqio rouge_score sacrebleu sentencepiece","metadata":{"id":"gLlSmmG0bvkZ","outputId":"33543b8d-c844-4d13-8afd-06dc02d463bd","execution":{"iopub.status.busy":"2021-07-10T15:16:59.068242Z","iopub.execute_input":"2021-07-10T15:16:59.068602Z","iopub.status.idle":"2021-07-10T15:18:08.406383Z","shell.execute_reply.started":"2021-07-10T15:16:59.068565Z","shell.execute_reply":"2021-07-10T15:18:08.40547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone -q https://github.com/lcl-hse/heptabot -b tensorflow\n%cd heptabot\n!mv scripts/colab-run/* .\n!mv scripts/tpu-run/* .\n!chmod +x colab_run.sh\n!chmod +x tpu_run.sh\n!sed -i -e 's/mamba/conda/g' colab_setup.sh\n!chmod +x colab_setup.sh","metadata":{"id":"S22whxr0UDl4","outputId":"92d07907-6681-47dc-c5e0-d1088415e69f","execution":{"iopub.status.busy":"2021-07-10T15:18:08.407984Z","iopub.execute_input":"2021-07-10T15:18:08.408414Z","iopub.status.idle":"2021-07-10T15:18:14.496462Z","shell.execute_reply.started":"2021-07-10T15:18:08.408366Z","shell.execute_reply":"2021-07-10T15:18:14.495114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!time bash colab_setup.sh","metadata":{"execution":{"iopub.status.busy":"2021-07-10T15:18:14.499048Z","iopub.execute_input":"2021-07-10T15:18:14.499515Z","iopub.status.idle":"2021-07-10T15:27:37.021598Z","shell.execute_reply.started":"2021-07-10T15:18:14.499464Z","shell.execute_reply":"2021-07-10T15:27:37.019942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir output\n!cp -r static output\n!mkdir raw","metadata":{"id":"jR9gSsJS4Ed4","execution":{"iopub.status.busy":"2021-07-10T15:27:37.025357Z","iopub.execute_input":"2021-07-10T15:27:37.025778Z","iopub.status.idle":"2021-07-10T15:27:39.333865Z","shell.execute_reply.started":"2021-07-10T15:27:37.025732Z","shell.execute_reply":"2021-07-10T15:27:39.332527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import subprocess\nfrom time import sleep\n\nsubprocess.Popen([\"/bin/bash\", os.path.join(os.path.realpath(\".\"), \"colab_run.sh\")])\nsleep(70)","metadata":{"id":"6N7JEiqs68jS","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport os\nimport pickle\nimport IPython","metadata":{"id":"P3EpipTbNRTC","execution":{"iopub.status.busy":"2021-07-10T15:29:04.978389Z","iopub.execute_input":"2021-07-10T15:29:04.978765Z","iopub.status.idle":"2021-07-10T15:29:04.98365Z","shell.execute_reply.started":"2021-07-10T15:29:04.978732Z","shell.execute_reply":"2021-07-10T15:29:04.982468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get the texts\n\nThe textual data is downloaded in this part. Here we use 3 essays from [REALEC](https://realec.org/) as example data; you should, however, change this part to process the texts you need.","metadata":{"id":"CzdqmwWb-iGy"}},{"cell_type":"code","source":"!mkdir input\n\n!wget -q \"https://realec.org/ajax.cgi?action=downloadFile&collection=%2Fexam%2FExam2015%2F&document=2015_KT_12_2&extension=txt&protocol=1\" -O ./input/KT_12_2.txt\n!wget -q \"https://realec.org/ajax.cgi?action=downloadFile&collection=%2Fexam%2FExam2014%2F&document=2014_ESha_2_1&extension=txt&protocol=1\" -O ./input/ESha_2_1.txt\n!wget -q \"https://realec.org/ajax.cgi?action=downloadFile&collection=%2Fexam%2FExam2016%2F&document=2016_LKa_2_2&extension=txt&protocol=1\" -O ./input/LKa_2_2.txt\n\nfiles = [\"KT_12_2.txt\", \"ESha_2_1.txt\", \"LKa_2_2.txt\"]\ntextdict = {}\n\nfor f in files:\n  with open(os.path.join(\"input\", f), \"r\", encoding=\"utf-8\") as infile:\n    textdict[f[:-4]] = infile.read()","metadata":{"id":"iwJuULSeGVrY","execution":{"iopub.status.busy":"2021-07-10T15:29:06.728653Z","iopub.execute_input":"2021-07-10T15:29:06.729005Z","iopub.status.idle":"2021-07-10T15:29:12.40738Z","shell.execute_reply.started":"2021-07-10T15:29:06.728975Z","shell.execute_reply":"2021-07-10T15:29:12.40591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Important**: If you got here from the error page on `heptabot` website stating \"*In order to maintain server resources and stable uptime, we limit the amounts of data that can be processed via our Web interface*\", uncomment the following code (remove all the number signs) and upload the `generated.txt` file you got from our website:","metadata":{"id":"HJ-zfEsWu74t"}},{"cell_type":"code","source":"#from google.colab import files\n#files.upload()\n\n#textdict = {}\n\n#with open(\"generated.txt\", \"r\", encoding=\"utf-8\") as infile:\n  #textdict[\"generated\"] = infile.read()","metadata":{"id":"arLuNcdfurgo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In other cases, we recommend to put your files into the **`input`** folder for comprehensibility.","metadata":{"id":"IIsM9kc5hdbB"}},{"cell_type":"markdown","source":"Put all your texts in a `dict` with the name `textdict`, where keys are `str`'s with texts IDs (preferrably filenames without extension), while the actual data is stored also as `txt`'s in values, as such:","metadata":{"id":"-B3PrPIsFXlD"}},{"cell_type":"code","source":"texts = textdict\n\nassert all(type(k) is str for k in texts.keys())\nassert all(type(v) is str for v in texts.values())","metadata":{"id":"EyyuRVhfFXH9","execution":{"iopub.status.busy":"2021-07-10T15:29:12.409359Z","iopub.execute_input":"2021-07-10T15:29:12.409747Z","iopub.status.idle":"2021-07-10T15:29:12.415178Z","shell.execute_reply.started":"2021-07-10T15:29:12.409697Z","shell.execute_reply":"2021-07-10T15:29:12.414383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Process data with `heptabot`\n\nThe actual `heptabot` magic is performed here!\n\n**Important**: please choose the appropriate task type in the following cell. While `correction`, the default, is used to correct whole essays and only its pipeline incororates the error classification subroutine, you may also want to perform sentencewise correction. In this case, choose one of the identifiers of the relevant GEC tasks: `jfleg` (trained on JFLEG data) is for general sentencewise correction and should provide more diverse results, while `conll` (trained on CONLL-14 competition) and `bea` (trained on BEA-2019 competition) correct mainly grammar-related errors, for which case the grammar parsing data is appended to the sentence in the corresponding pipeline. Please note that `heptabot` expects whole paragraphs of text as data for `correction` and sentence-by-sentence structured data for other tasks, so make sure your file(s) contain single sentences separated by newlines if you wish to perform any other task than `correction`.","metadata":{"id":"VU9bIesEGctJ"}},{"cell_type":"code","source":"task_type = \"correction\"  #@param [\"correction\", \"jfleg\", \"conll\", \"bea\"] ","metadata":{"id":"59_4XO_DFghu","cellView":"form","execution":{"iopub.status.busy":"2021-07-10T15:29:12.897656Z","iopub.execute_input":"2021-07-10T15:29:12.897995Z","iopub.status.idle":"2021-07-10T15:29:12.902612Z","shell.execute_reply.started":"2021-07-10T15:29:12.897966Z","shell.execute_reply":"2021-07-10T15:29:12.901431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nchosen_one = random.choice(list(texts.keys()))\n\nprint(texts[chosen_one])","metadata":{"id":"zrzRsNNBKXxj","outputId":"805c87cb-a139-4ba6-b57f-91b766e871b3","execution":{"iopub.status.busy":"2021-07-10T15:29:14.247924Z","iopub.execute_input":"2021-07-10T15:29:14.24835Z","iopub.status.idle":"2021-07-10T15:29:14.254112Z","shell.execute_reply.started":"2021-07-10T15:29:14.248309Z","shell.execute_reply":"2021-07-10T15:29:14.253066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pickledata = (task_type, texts)\n\nwith open(\"./raw/process_texts.pkl\", \"wb\") as outpickle:\n  pickle.dump(pickledata, outpickle)","metadata":{"id":"ZRNwdsBS3wGf","execution":{"iopub.status.busy":"2021-07-10T15:29:53.338799Z","iopub.execute_input":"2021-07-10T15:29:53.339203Z","iopub.status.idle":"2021-07-10T15:29:53.344406Z","shell.execute_reply.started":"2021-07-10T15:29:53.339165Z","shell.execute_reply":"2021-07-10T15:29:53.343231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In order to get the advantage of using TPU, we split our process in three parts. First, we prepare our texts by splitting them into batches required by `heptabot`:","metadata":{"id":"b3rkI1AuPNJM"}},{"cell_type":"code","source":"%%bash\nsource activate heptabot\npython batchify_input.py","metadata":{"id":"PhS35WWpVQco","outputId":"ca9b2f4d-c91d-4241-e934-8134222babfb","execution":{"iopub.status.busy":"2021-07-10T15:30:01.535292Z","iopub.execute_input":"2021-07-10T15:30:01.535718Z","iopub.status.idle":"2021-07-10T15:30:02.036448Z","shell.execute_reply.started":"2021-07-10T15:30:01.535682Z","shell.execute_reply":"2021-07-10T15:30:02.035316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then we call the TPU process (this is where our `xxl` model runs inference on the texts):","metadata":{"id":"l_tJM4a4VQsk"}},{"cell_type":"code","source":"%%bash\npython tpu_model_run.py","metadata":{"execution":{"iopub.status.busy":"2021-07-10T15:30:12.458989Z","iopub.execute_input":"2021-07-10T15:30:12.459436Z","iopub.status.idle":"2021-07-10T15:33:50.375711Z","shell.execute_reply.started":"2021-07-10T15:30:12.459396Z","shell.execute_reply":"2021-07-10T15:33:50.374319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And then, finally, we glue our processed texts back together to produce the outputs:","metadata":{"id":"Zv4BhgkQak-5"}},{"cell_type":"code","source":"%%bash\nsource activate heptabot\npython process_output.py","metadata":{"id":"VymUL8RwadVd","outputId":"e75b8eaa-7457-4d6d-9ad2-a0a99aee0c5b","execution":{"iopub.status.busy":"2021-07-10T15:33:50.378241Z","iopub.execute_input":"2021-07-10T15:33:50.378742Z","iopub.status.idle":"2021-07-10T15:33:54.715582Z","shell.execute_reply.started":"2021-07-10T15:33:50.378675Z","shell.execute_reply":"2021-07-10T15:33:54.714226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Display the results\n\nFinally, in this section you can display the processed results.","metadata":{"id":"1cK8wUBgWsoD"}},{"cell_type":"code","source":"#This cell contains a function that makes pretty displaying work\ndef prepare_display(filekey):\n  template = \"\"\"<html><head>\n\t<meta charset=\"utf-8\">\n\t<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\">\n\t<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n\t<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\">\n\t<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\">\n\t<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js\"></script>\n\t<link href=\"https://getbootstrap.com/docs/3.3/dist/css/bootstrap.min.css\" rel=\"stylesheet\"><!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->\n\t<link href=\"https://getbootstrap.com/docs/3.3/assets/css/ie10-viewport-bug-workaround.css\" rel=\"stylesheet\"><!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->\n\t<link href=\"https://fonts.googleapis.com/css2?family=Kanit&family=Mukta&family=PT+Sans&family=PT+Serif&family=Ubuntu+Mono&display=swap\" rel=\"stylesheet\">\n<style>\n{0}\n</style>\n<script type=\"text/javascript\">\n{1}\n</script>\n</head>\n<body>\n<div class=\"header2\">{2}</div><br>\n{3}\n</body></html>\"\"\"\n\n  with open(\"static/result/style.css\", \"r\") as inhtml:\n    style = inhtml.read()\n  with open(\"static/result/engine.js\", \"r\") as inhtml:\n    script = inhtml.read().replace(\"var em;\", \"var em=18;\").replace(\"elemtitle.style.left = varleft + 'px';\", \"elemtitle.style.left = varleft - 70 + 'px';\")\n  with open(os.path.join('./output', filekey + \".html\"), \"r\") as inhtml:\n    htmlcont = inhtml.read()\n  tt = re.search(r'<div class=\"header2\">(.*?)</div>', htmlcont, flags=re.DOTALL).group(1)\n  result_div = re.search(r'<div id=\"resulta\".*?\\n', htmlcont).group(0)\n  outcont = template.format(style, script, tt, result_div)\n  with open(\"display.html\", \"w\", encoding=\"utf-8\") as outhtml:\n    outhtml.write(outcont)","metadata":{"id":"vOCnVcL2afCl","cellView":"form","execution":{"iopub.status.busy":"2021-07-10T15:33:54.718292Z","iopub.execute_input":"2021-07-10T15:33:54.718776Z","iopub.status.idle":"2021-07-10T15:33:54.730002Z","shell.execute_reply.started":"2021-07-10T15:33:54.718723Z","shell.execute_reply":"2021-07-10T15:33:54.728701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#@markdown Enter the desired text ID below to pretty-print the result\ndisplay_id = chosen_one  #@param {type: \"string\"}\n\nprepare_display(display_id)\nIPython.display.HTML(filename='display.html')","metadata":{"id":"N7iwGpiIZ0cS","outputId":"868977b3-f350-4fc2-812b-ec505ff8f3db","execution":{"iopub.status.busy":"2021-07-10T15:33:54.731467Z","iopub.execute_input":"2021-07-10T15:33:54.731913Z","iopub.status.idle":"2021-07-10T15:33:54.756438Z","shell.execute_reply.started":"2021-07-10T15:33:54.73188Z","shell.execute_reply":"2021-07-10T15:33:54.755456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Download the results\n\nNow, you may also want to get the texts processed by `heptabot`. The code below will generate a link to download the processed texts directly to your computer: unzip them to view the results as they would be displayed in the web version.","metadata":{"id":"b3c_74rjoxAP"}},{"cell_type":"code","source":"!zip -q heptabot_processed.zip -r output","metadata":{"id":"H22D7MHZowmf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from IPython.display import FileLink\n\n#FileLink(r'heptabot_processed.zip')","metadata":{"id":"V7XuyUELVy-t","outputId":"6aefbd26-7e21-4cb7-82ed-42e2f75369b1"},"execution_count":null,"outputs":[]}]}