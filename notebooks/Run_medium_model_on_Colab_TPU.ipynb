{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Run medium model on Colab TPU.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "fcyITR3j-Q-E"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YONnGjpAYUdU"
      },
      "source": [
        "\n",
        "<a href=\"https://colab.research.google.com/github/lcl-hse/heptabot/blob/gpu-tpu/notebooks/Run_medium_model_on_Colab_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCpdqIxO9XlR"
      },
      "source": [
        "# Run heptabot `medium` model on Colab TPU\n",
        "\n",
        "This notebook lets you to process data with our `medium` model in Google Colab TPU environments, which provides the highest speed and allows to process huge chunks of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdmtepIzQcnh"
      },
      "source": [
        "As Colab has recently switched to Python 3.7 and our dependency `spaCy 1.9.0` supports only Python 3.6, we use `mamba` to ensure that we get the right packages in our environment. To get `mamba`, you should execute the following cell (click the '‚ñ∑' button). Please note that the runtime will restart after that, so don't schedule the rest of the cells to execute just yet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAZ11nESX6qt",
        "outputId": "b3a562ce-9703-4f71-f3ab-02393f37a6eb"
      },
      "source": [
        "!pip install -q condacolab==0.1.1\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‚è¨ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "üì¶ Installing...\n",
            "üìå Adjusting configuration...\n",
            "ü©π Patching environment...\n",
            "‚è≤ Done in 0:00:40\n",
            "üîÅ Restarting kernel...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WILmgslscMTd"
      },
      "source": [
        "After your runtime is restarted, execute the following cell to set some environmental variables:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9eZYBUZVfLx"
      },
      "source": [
        "import os\n",
        "\n",
        "model_type = \"medium\"\n",
        "# The steps are largely the same between medium and xxl models. \n",
        "# However, we keep this, as it is advantageous to run medium model in Google Colab, while xxl ‚Äì in Kaggle, and these environments have their differences\n",
        "\n",
        "os.environ[\"MODEL_PLACE\"] = \"tpu\"\n",
        "os.environ[\"HPT_MODEL_TYPE\"] = model_type\n",
        "\n",
        "if model_type == \"xxl\":\n",
        "    os.environ[\"CHECKPOINT_STEP\"] = \"1014000\"\n",
        "    os.environ[\"TPU_TOPOLOGY\"] = \"v3-8\"\n",
        "else:\n",
        "    os.environ[\"CHECKPOINT_STEP\"] = \"1003800\"\n",
        "    os.environ[\"TPU_TOPOLOGY\"] = \"v2-8\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcyITR3j-Q-E"
      },
      "source": [
        "## Prepare environment\n",
        "\n",
        "Now click the '‚ñ∑' on this group of cells. The code below will install the environment for `heptabot`, which takes around 10 minutes to execute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLlSmmG0bvkZ",
        "outputId": "82d58b44-5a7d-4e33-ff83-266d9e7267ef"
      },
      "source": [
        "!pip install -qq t5==0.9.0 seqio rouge_score sacrebleu sentencepiece"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 230 kB 5.3 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 249 kB 10.2 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 54 kB 2.1 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.2 MB 11.2 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46 kB 3.9 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8.8 MB 21.5 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11.5 MB 58.4 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366 kB 64.5 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28.5 MB 31 kB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.0 MB 45.8 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 831.4 MB 2.2 kB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.5 MB 23.7 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.3 MB 27.0 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22.3 MB 2.2 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 132 kB 60.2 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.7 MB 71 kB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.6 MB 25.1 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 829 kB 44.9 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.0 MB 52.5 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 721 kB 46.7 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40 kB 5.3 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 636 kB 74.5 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 895 kB 67.5 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.3 MB 42.2 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67 kB 5.0 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 510 kB 48.8 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97 kB 6.7 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 303 kB 73.7 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 247 kB 71.2 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.0 MB 44.4 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 86 kB 5.9 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48 kB 5.3 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 53 kB 2.2 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198 kB 70.5 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 129 kB 76.0 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 454.3 MB 17 kB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 108 kB 63.9 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57 kB 4.8 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.0 MB 69.0 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 65 kB 3.7 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 462 kB 46.4 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.0 MB 28.9 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14.8 MB 156 kB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42 kB 1.2 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.2 MB 67.5 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.0 MB 67.4 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 288 kB 79.5 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97 kB 6.1 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.9 MB 17.6 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 152 kB 59.6 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 781 kB 58.1 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 155 kB 59.0 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77 kB 5.7 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 146 kB 60.4 MB/s \n",
            "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for promise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S22whxr0UDl4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e743294-0077-4519-fa5b-cf666c1d9dd5"
      },
      "source": [
        "!git clone -q https://github.com/lcl-hse/heptabot -b gpu-tpu\n",
        "%cd heptabot\n",
        "!mv scripts/colab-run/* .\n",
        "!mv scripts/tpu-run/* .\n",
        "!chmod +x colab_run.sh\n",
        "!chmod +x tpu_run.sh\n",
        "!mv scripts/measures/* .\n",
        "!chmod +x run_measures.sh"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/heptabot\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV_3ymt_UNd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6435d157-2e56-45a3-d7ed-be0551826dd1"
      },
      "source": [
        "!time bash colab_setup.sh"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing virtual environment with python 3.6.9\n",
            "  Package             Version  Build               Channel                    Size\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  Install:\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "\n",
            "\u001b[32m  _libgcc_mutex   \u001b[00m        0.1  conda_forge         conda-forge/linux-64\u001b[32m     Cached\u001b[00m\n",
            "\u001b[32m  _openmp_mutex   \u001b[00m        4.5  1_gnu               conda-forge/linux-64\u001b[32m     Cached\u001b[00m\n",
            "\u001b[32m  ca-certificates \u001b[00m  2021.5.30  ha878542_0          conda-forge/linux-64     136 KB\n",
            "\u001b[32m  certifi         \u001b[00m  2021.5.30  py36h5fab9bb_0      conda-forge/linux-64     141 KB\n",
            "\u001b[32m  ld_impl_linux-64\u001b[00m     2.36.1  hea4e1c9_2          conda-forge/linux-64     667 KB\n",
            "\u001b[32m  libffi          \u001b[00m      3.2.1  he1b5a44_1007       conda-forge/linux-64      47 KB\n",
            "\u001b[32m  libgcc-ng       \u001b[00m     11.1.0  hc902ee8_5          conda-forge/linux-64     907 KB\n",
            "\u001b[32m  libgomp         \u001b[00m     11.1.0  hc902ee8_5          conda-forge/linux-64     428 KB\n",
            "\u001b[32m  libstdcxx-ng    \u001b[00m     11.1.0  h56837e0_5          conda-forge/linux-64       4 MB\n",
            "\u001b[32m  ncurses         \u001b[00m        6.2  h58526e2_4          conda-forge/linux-64\u001b[32m     Cached\u001b[00m\n",
            "\u001b[32m  openssl         \u001b[00m     1.1.1k  h7f98852_0          conda-forge/linux-64       2 MB\n",
            "\u001b[32m  pip             \u001b[00m     21.2.1  pyhd8ed1ab_0        conda-forge/noarch         1 MB\n",
            "\u001b[32m  python          \u001b[00m      3.6.9  h9d8adfe_0_cpython  conda-forge/linux-64      34 MB\n",
            "\u001b[32m  python_abi      \u001b[00m        3.6  2_cp36m             conda-forge/linux-64       4 KB\n",
            "\u001b[32m  readline        \u001b[00m        8.1  h46c0cb4_0          conda-forge/linux-64     295 KB\n",
            "\u001b[32m  setuptools      \u001b[00m     49.6.0  py36h5fab9bb_3      conda-forge/linux-64     936 KB\n",
            "\u001b[32m  sqlite          \u001b[00m     3.36.0  h9cd32fc_0          conda-forge/linux-64       1 MB\n",
            "\u001b[32m  tk              \u001b[00m     8.6.10  hed695b0_1          conda-forge/linux-64       3 MB\n",
            "\u001b[32m  wheel           \u001b[00m     0.36.2  pyhd3deb0d_0        conda-forge/noarch  \u001b[32m     Cached\u001b[00m\n",
            "\u001b[32m  xz              \u001b[00m      5.2.5  h516909a_1          conda-forge/linux-64\u001b[32m     Cached\u001b[00m\n",
            "\u001b[32m  zlib            \u001b[00m     1.2.11  h516909a_1010       conda-forge/linux-64\u001b[32m     Cached\u001b[00m\n",
            "\n",
            "  Summary:\n",
            "\n",
            "  Install: 21 packages\n",
            "\n",
            "  Total download: 50 MB\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\n",
            "Installing requirements\n",
            "  Package                           Version  Build                            Channel                    Size\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  Install:\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "\n",
            "\u001b[32m  argon2-cffi                  \u001b[00m      20.1.0  py36h8f6f2f9_2                   conda-forge/linux-64      47 KB\n",
            "\u001b[32m  async_generator              \u001b[00m        1.10  py_0                             conda-forge/noarch        18 KB\n",
            "\u001b[32m  attrs                        \u001b[00m      21.2.0  pyhd8ed1ab_0                     conda-forge/noarch        44 KB\n",
            "\u001b[32m  backcall                     \u001b[00m       0.2.0  pyh9f0ad1d_0                     conda-forge/noarch        13 KB\n",
            "\u001b[32m  backports                    \u001b[00m         1.0  py36_1                           conda-forge/linux-64       4 KB\n",
            "\u001b[32m  backports.functools_lru_cache\u001b[00m       1.6.4  pyhd8ed1ab_0                     conda-forge/noarch         9 KB\n",
            "\u001b[32m  blas                         \u001b[00m         1.1  openblas                         conda-forge/linux-64       1 KB\n",
            "\u001b[32m  bleach                       \u001b[00m       3.3.1  pyhd8ed1ab_0                     conda-forge/noarch       111 KB\n",
            "\u001b[32m  brotlipy                     \u001b[00m       0.7.0  py36he6145b8_1001                conda-forge/linux-64     347 KB\n",
            "\u001b[32m  cffi                         \u001b[00m      1.14.4  py36h211aa47_0                   conda-forge/linux-64     224 KB\n",
            "\u001b[32m  chardet                      \u001b[00m       4.0.0  py36h5fab9bb_1                   conda-forge/linux-64     219 KB\n",
            "\u001b[32m  charset-normalizer           \u001b[00m       2.0.0  pyhd8ed1ab_0                     conda-forge/noarch        32 KB\n",
            "\u001b[32m  click                        \u001b[00m       8.0.1  py36h5fab9bb_0                   conda-forge/linux-64     145 KB\n",
            "\u001b[32m  cryptography                 \u001b[00m       3.4.7  py36hb60f036_0                   conda-forge/linux-64       1 MB\n",
            "\u001b[32m  cymem                        \u001b[00m      1.31.2  py36_0                           conda-forge/linux-64      67 KB\n",
            "\u001b[32m  cytoolz                      \u001b[00m       0.8.2  py36_0                           conda-forge/linux-64       1 MB\n",
            "\u001b[32m  dataclasses                  \u001b[00m         0.8  pyh787bdff_0                     conda-forge/noarch        22 KB\n",
            "\u001b[32m  decorator                    \u001b[00m       5.0.9  pyhd8ed1ab_0                     conda-forge/noarch        11 KB\n",
            "\u001b[32m  defusedxml                   \u001b[00m       0.7.1  pyhd8ed1ab_0                     conda-forge/noarch        23 KB\n",
            "\u001b[32m  diff-match-patch             \u001b[00m    20200713  pyh9f0ad1d_0                     conda-forge/noarch        38 KB\n",
            "\u001b[32m  dill                         \u001b[00m       0.2.9  py36_0                           conda-forge/linux-64     113 KB\n",
            "\u001b[32m  entrypoints                  \u001b[00m         0.3  py36h9f0ad1d_1002                conda-forge/linux-64      13 KB\n",
            "\u001b[32m  flask                        \u001b[00m       2.0.1  pyhd8ed1ab_0                     conda-forge/noarch        70 KB\n",
            "\u001b[32m  ftfy                         \u001b[00m       4.4.2  py36_0                           conda-forge/linux-64      51 KB\n",
            "\u001b[32m  html5lib                     \u001b[00m         1.1  pyh9f0ad1d_0                     conda-forge/noarch        89 KB\n",
            "\u001b[32m  idna                         \u001b[00m         3.2  pyhd3eb1b0_0                     pkgs/main/noarch          48 KB\n",
            "\u001b[32m  importlib-metadata           \u001b[00m       4.6.1  py36h5fab9bb_0                   conda-forge/linux-64      31 KB\n",
            "\u001b[32m  importlib_metadata           \u001b[00m       4.6.1  hd8ed1ab_0                       conda-forge/noarch         3 KB\n",
            "\u001b[32m  ipykernel                    \u001b[00m       5.5.5  py36hcb3619a_0                   conda-forge/linux-64     166 KB\n",
            "\u001b[32m  ipython                      \u001b[00m      7.16.1  py36he448a4c_2                   conda-forge/linux-64       1 MB\n",
            "\u001b[32m  ipython_genutils             \u001b[00m       0.2.0  py36_0                           conda-forge/linux-64      36 KB\n",
            "\u001b[32m  ipywidgets                   \u001b[00m       7.6.3  pyhd3deb0d_0                     conda-forge/noarch       101 KB\n",
            "\u001b[32m  itsdangerous                 \u001b[00m       2.0.1  pyhd8ed1ab_0                     conda-forge/noarch        17 KB\n",
            "\u001b[32m  jedi                         \u001b[00m      0.17.2  py36h9f0ad1d_1                   conda-forge/linux-64     946 KB\n",
            "\u001b[32m  jinja2                       \u001b[00m       3.0.1  pyhd8ed1ab_0                     conda-forge/noarch        99 KB\n",
            "\u001b[32m  joblib                       \u001b[00m       1.0.1  pyhd8ed1ab_0                     conda-forge/noarch       206 KB\n",
            "\u001b[32m  jsonschema                   \u001b[00m       3.2.0  py36h9f0ad1d_1                   conda-forge/linux-64      89 KB\n",
            "\u001b[32m  jupyter_client               \u001b[00m      6.1.12  pyhd8ed1ab_0                     conda-forge/noarch        79 KB\n",
            "\u001b[32m  jupyter_core                 \u001b[00m       4.7.1  py36h5fab9bb_0                   conda-forge/linux-64      72 KB\n",
            "\u001b[32m  jupyterlab_pygments          \u001b[00m       0.1.2  pyh9f0ad1d_0                     conda-forge/noarch         8 KB\n",
            "\u001b[32m  jupyterlab_widgets           \u001b[00m       1.0.0  pyhd8ed1ab_1                     conda-forge/noarch       130 KB\n",
            "\u001b[32m  libgcc                       \u001b[00m       7.2.0  h69d50b8_2                       conda-forge/linux-64     304 KB\n",
            "\u001b[32m  libgfortran-ng               \u001b[00m       7.5.0  h14aa051_19                      conda-forge/linux-64      22 KB\n",
            "\u001b[32m  libgfortran4                 \u001b[00m       7.5.0  h14aa051_19                      conda-forge/linux-64       1 MB\n",
            "\u001b[32m  libsodium                    \u001b[00m      1.0.18  h516909a_1                       conda-forge/linux-64     366 KB\n",
            "\u001b[32m  markupsafe                   \u001b[00m       2.0.1  py36h8f6f2f9_0                   conda-forge/linux-64      22 KB\n",
            "\u001b[32m  mistune                      \u001b[00m       0.8.4  py36h8f6f2f9_1004                conda-forge/linux-64      54 KB\n",
            "\u001b[32m  murmurhash                   \u001b[00m      0.26.4  py36_0                           conda-forge/linux-64      37 KB\n",
            "\u001b[32m  nbclient                     \u001b[00m       0.5.3  pyhd8ed1ab_0                     conda-forge/noarch        67 KB\n",
            "\u001b[32m  nbconvert                    \u001b[00m       6.0.7  py36h5fab9bb_3                   conda-forge/linux-64     533 KB\n",
            "\u001b[32m  nbformat                     \u001b[00m       5.1.3  pyhd8ed1ab_0                     conda-forge/noarch        47 KB\n",
            "\u001b[32m  nest-asyncio                 \u001b[00m       1.5.1  pyhd8ed1ab_0                     conda-forge/noarch         9 KB\n",
            "\u001b[32m  nltk                         \u001b[00m       3.6.2  pyhd8ed1ab_0                     conda-forge/noarch         1 MB\n",
            "\u001b[32m  notebook                     \u001b[00m       6.4.0  py36h06a4308_0                   pkgs/main/linux-64         4 MB\n",
            "\u001b[32m  numpy                        \u001b[00m      1.12.1  py36_blas_openblash1522bff_1001  conda-forge/linux-64       4 MB\n",
            "\u001b[32m  openblas                     \u001b[00m       0.3.3  h9ac9557_1001                    conda-forge/linux-64      16 MB\n",
            "\u001b[32m  packaging                    \u001b[00m        21.0  pyhd8ed1ab_0                     conda-forge/noarch        35 KB\n",
            "\u001b[32m  pandas                       \u001b[00m      0.24.2  py36hf484d3e_0                   conda-forge/linux-64      11 MB\n",
            "\u001b[32m  pandoc                       \u001b[00m      2.14.1  h7f98852_0                       conda-forge/linux-64      12 MB\n",
            "\u001b[32m  pandocfilters                \u001b[00m       1.4.3  py36h06a4308_1                   pkgs/main/linux-64        14 KB\n",
            "\u001b[32m  parso                        \u001b[00m       0.7.1  pyh9f0ad1d_0                     conda-forge/noarch        70 KB\n",
            "\u001b[32m  pexpect                      \u001b[00m       4.8.0  py36h9f0ad1d_1                   conda-forge/linux-64      79 KB\n",
            "\u001b[32m  pickleshare                  \u001b[00m       0.7.5  py36h9f0ad1d_1002                conda-forge/linux-64      13 KB\n",
            "\u001b[32m  plac                         \u001b[00m       0.9.6  py36_0                           conda-forge/linux-64      36 KB\n",
            "\u001b[32m  preshed                      \u001b[00m       1.0.1  py36hf484d3e_1000                conda-forge/linux-64      83 KB\n",
            "\u001b[32m  prometheus_client            \u001b[00m      0.11.0  pyhd8ed1ab_0                     conda-forge/noarch        46 KB\n",
            "\u001b[32m  prompt-toolkit               \u001b[00m      3.0.19  pyha770c72_0                     conda-forge/noarch       244 KB\n",
            "\u001b[32m  ptyprocess                   \u001b[00m       0.7.0  pyhd3deb0d_0                     conda-forge/noarch        16 KB\n",
            "\u001b[32m  pycparser                    \u001b[00m        2.20  pyh9f0ad1d_2                     conda-forge/noarch  \u001b[32m     Cached\u001b[00m\n",
            "\u001b[32m  pygments                     \u001b[00m       2.9.0  pyhd8ed1ab_0                     conda-forge/noarch       754 KB\n",
            "\u001b[32m  pyopenssl                    \u001b[00m      20.0.1  pyhd8ed1ab_0                     conda-forge/noarch  \u001b[32m     Cached\u001b[00m\n",
            "\u001b[32m  pyparsing                    \u001b[00m       2.4.7  pyh9f0ad1d_0                     conda-forge/noarch        60 KB\n",
            "\u001b[32m  pyro4                        \u001b[00m        4.80  pyh9f0ad1d_0                     conda-forge/noarch        67 KB\n",
            "\u001b[32m  pyrsistent                   \u001b[00m      0.17.3  py36h8f6f2f9_2                   conda-forge/linux-64      89 KB\n",
            "\u001b[32m  pysocks                      \u001b[00m       1.7.1  py36h5fab9bb_3                   conda-forge/linux-64      27 KB\n",
            "\u001b[32m  python-dateutil              \u001b[00m       2.8.2  pyhd8ed1ab_0                     conda-forge/noarch       240 KB\n",
            "\u001b[32m  python-levenshtein           \u001b[00m      0.12.2  py36h8f6f2f9_0                   conda-forge/linux-64      80 KB\n",
            "\u001b[32m  pytz                         \u001b[00m      2021.1  pyhd8ed1ab_0                     conda-forge/noarch       239 KB\n",
            "\u001b[32m  pyzmq                        \u001b[00m      22.1.0  py36h7068817_0                   conda-forge/linux-64     528 KB\n",
            "\u001b[32m  regex                        \u001b[00m  2017.11.09  py36_0                           conda-forge/linux-64     670 KB\n",
            "\u001b[32m  requests                     \u001b[00m      2.26.0  pyhd8ed1ab_0                     conda-forge/noarch        52 KB\n",
            "\u001b[32m  send2trash                   \u001b[00m       1.7.1  pyhd8ed1ab_0                     conda-forge/noarch        17 KB\n",
            "\u001b[32m  serpent                      \u001b[00m        1.40  pyhd8ed1ab_1                     conda-forge/noarch        12 KB\n",
            "\u001b[32m  six                          \u001b[00m      1.16.0  pyh6c4a22f_0                     conda-forge/noarch        14 KB\n",
            "\u001b[32m  spacy                        \u001b[00m       1.9.0  np112py36_1                      conda-forge/linux-64       8 MB\n",
            "\u001b[32m  termcolor                    \u001b[00m       1.1.0  py36_1                           conda-forge/linux-64       6 KB\n",
            "\u001b[32m  terminado                    \u001b[00m      0.10.1  py36h5fab9bb_0                   conda-forge/linux-64      26 KB\n",
            "\u001b[32m  testpath                     \u001b[00m       0.5.0  pyhd8ed1ab_0                     conda-forge/noarch        86 KB\n",
            "\u001b[32m  thinc                        \u001b[00m       6.5.2  np112py36_0                      conda-forge/linux-64       2 MB\n",
            "\u001b[32m  toolz                        \u001b[00m      0.11.1  py_0                             conda-forge/noarch        46 KB\n",
            "\u001b[32m  tornado                      \u001b[00m         6.1  py36h8f6f2f9_1                   conda-forge/linux-64     643 KB\n",
            "\u001b[32m  tqdm                         \u001b[00m      4.61.2  pyhd8ed1ab_1                     conda-forge/noarch        80 KB\n",
            "\u001b[32m  traitlets                    \u001b[00m       4.3.3  py36h9f0ad1d_1                   conda-forge/linux-64     133 KB\n",
            "\u001b[32m  typing_extensions            \u001b[00m    3.10.0.0  pyha770c72_0                     conda-forge/noarch        28 KB\n",
            "\u001b[32m  ujson                        \u001b[00m       4.0.2  py36hc4f0c31_0                   conda-forge/linux-64      48 KB\n",
            "\u001b[32m  urllib3                      \u001b[00m      1.26.6  pyhd8ed1ab_0                     conda-forge/noarch        99 KB\n",
            "\u001b[32m  wcwidth                      \u001b[00m       0.2.5  pyh9f0ad1d_2                     conda-forge/noarch        33 KB\n",
            "\u001b[32m  webencodings                 \u001b[00m       0.5.1  py_1                             conda-forge/noarch        12 KB\n",
            "\u001b[32m  werkzeug                     \u001b[00m       2.0.1  pyhd8ed1ab_0                     conda-forge/noarch       219 KB\n",
            "\u001b[32m  widgetsnbextension           \u001b[00m       3.5.1  py36h9f0ad1d_4                   conda-forge/linux-64       2 MB\n",
            "\u001b[32m  wrapt                        \u001b[00m      1.12.1  py36h8f6f2f9_3                   conda-forge/linux-64      47 KB\n",
            "\u001b[32m  zeromq                       \u001b[00m       4.3.4  h9c3ff4c_0                       conda-forge/linux-64     352 KB\n",
            "\u001b[32m  zipp                         \u001b[00m       3.5.0  pyhd8ed1ab_0                     conda-forge/noarch        12 KB\n",
            "\n",
            "  Upgrade:\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "\n",
            "\u001b[31m  ca-certificates              \u001b[00m   2021.5.30  ha878542_0                       installed                      \n",
            "\u001b[32m  ca-certificates              \u001b[00m    2021.7.5  h06a4308_1                       pkgs/main/linux-64       113 KB\n",
            "\n",
            "  Summary:\n",
            "\n",
            "  Install: 103 packages\n",
            "  Upgrade: 1 packages\n",
            "\n",
            "  Total download: 75 MB\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... Enabling notebook extension jupyter-js-widgets/extension...\n",
            "Paths used for configuration of notebook: \n",
            "    \t/usr/local/envs/heptabot/etc/jupyter/nbconfig/notebook.d/widgetsnbextension.json\n",
            "    \t/usr/local/envs/heptabot/etc/jupyter/nbconfig/notebook.json\n",
            "Paths used for configuration of notebook: \n",
            "    \t/usr/local/envs/heptabot/etc/jupyter/nbconfig/notebook.d/widgetsnbextension.json\n",
            "      - Validating: \u001b[32mOK\u001b[0m\n",
            "Paths used for configuration of notebook: \n",
            "    \t/usr/local/envs/heptabot/etc/jupyter/nbconfig/notebook.d/widgetsnbextension.json\n",
            "    \t/usr/local/envs/heptabot/etc/jupyter/nbconfig/notebook.json\n",
            "\n",
            "done\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 494 kB 5.2 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44 kB 2.1 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 320.4 MB 39 kB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 320.4 MB 45 kB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.6 MB 26.8 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 753.2 MB 2.3 kB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17.3 MB 63 kB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 884 kB 50.0 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 69.2 MB 30 kB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 62 kB 934 kB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48 kB 4.7 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.5 MB 58.2 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.9 MB 42.4 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.0 MB 42.2 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 26.1 MB 17 kB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.3 MB 36.1 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 459 kB 75.8 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.2 MB 71.6 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.0 MB 41.1 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20.6 MB 1.3 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11.5 MB 56.0 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 22.2 MB 10.5 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.4 MB 48.8 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49 kB 5.1 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.1 MB 56.7 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.0 MB 56.5 MB/s \n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'python-levenshtein' candidate (version 0.12.0 at https://files.pythonhosted.org/packages/42/a9/d1785c85ebf9b7dfacd08938dd028209c34a0ea3b1bcdb895208bd40a67d/python-Levenshtein-0.12.0.tar.gz#sha256=033a11de5e3d19ea25c9302d11224e1a1898fe5abd23c61c7c360c25195e3eb1 (from https://pypi.org/simple/python-levenshtein/))\n",
            "Reason for being yanked: Insecure, upgrade to 0.12.1\u001b[0m\n",
            "\u001b[?25h  Building wheel for func-timeout (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\u001b[33mCache entry deserialization failed, entry ignored\u001b[0m\n",
            "\u001b[K    100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.6MB 725kB/s \n",
            "\u001b[?25h\n",
            "Setting up nltk and spaCy\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "\n",
            "    Downloading en_core_web_sm-1.2.0/en_core_web_sm-1.2.0.tar.gz\n",
            "\n",
            "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-1.2.0/en_core_web_sm-1.2.0.tar.gz\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-1.2.0/en_core_web_sm-1.2.0.tar.gz (52.2 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 52.2 MB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<2.0.0,>=1.7.0 in /usr/local/envs/heptabot/lib/python3.6/site-packages (from en-core-web-sm==1.2.0) (1.9.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/envs/heptabot/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0) (1.16.1)\n",
            "Requirement already satisfied: murmurhash<0.27,>=0.26 in /usr/local/envs/heptabot/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0) (0.26.4)\n",
            "Requirement already satisfied: cymem<1.32,>=1.30 in /usr/local/envs/heptabot/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0) (1.31.2)\n",
            "Requirement already satisfied: preshed<2.0.0,>=1.0.0 in /usr/local/envs/heptabot/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0) (1.0.1)\n",
            "Requirement already satisfied: thinc<6.6.0,>=6.5.0 in /usr/local/envs/heptabot/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0) (6.5.2)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/envs/heptabot/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0) (0.9.6)\n",
            "Collecting pip<10.0.0,>=9.0.0\n",
            "  Downloading pip-9.0.3-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.4 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/envs/heptabot/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0) (1.16.0)\n",
            "Requirement already satisfied: pathlib in /usr/local/envs/heptabot/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0) (1.0.1)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/envs/heptabot/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0) (4.0.2)\n",
            "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/envs/heptabot/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0) (0.2.9)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/envs/heptabot/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0) (2.26.0)\n",
            "Requirement already satisfied: regex<2017.12.1,>=2017.4.1 in /usr/local/envs/heptabot/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0) (2017.11.9)\n",
            "Requirement already satisfied: ftfy<5.0.0,>=4.4.2 in /usr/local/envs/heptabot/lib/python3.6/site-packages (from spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0) (4.4.2)\n",
            "Requirement already satisfied: html5lib in /usr/local/envs/heptabot/lib/python3.6/site-packages (from ftfy<5.0.0,>=4.4.2->spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0) (1.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/envs/heptabot/lib/python3.6/site-packages (from ftfy<5.0.0,>=4.4.2->spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0) (0.2.5)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/envs/heptabot/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0) (3.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/envs/heptabot/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0) (1.26.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/heptabot/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0) (2021.5.30)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/envs/heptabot/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0) (2.0.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/envs/heptabot/lib/python3.6/site-packages (from thinc<6.6.0,>=6.5.0->spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0) (1.12.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/envs/heptabot/lib/python3.6/site-packages (from thinc<6.6.0,>=6.5.0->spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0) (4.61.2)\n",
            "Requirement already satisfied: cytoolz<0.9,>=0.8 in /usr/local/envs/heptabot/lib/python3.6/site-packages (from thinc<6.6.0,>=6.5.0->spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0) (0.8.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/envs/heptabot/lib/python3.6/site-packages (from thinc<6.6.0,>=6.5.0->spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0) (1.1.0)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/envs/heptabot/lib/python3.6/site-packages (from cytoolz<0.9,>=0.8->thinc<6.6.0,>=6.5.0->spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0) (0.11.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/envs/heptabot/lib/python3.6/site-packages (from html5lib->ftfy<5.0.0,>=4.4.2->spacy<2.0.0,>=1.7.0->en-core-web-sm==1.2.0) (0.5.1)\n",
            "Building wheels for collected packages: en-core-web-sm\n",
            "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-sm: filename=en_core_web_sm-1.2.0-py3-none-any.whl size=53385727 sha256=31717b50efbb413b0c3d635887c91e5b689e4ecca608e3c6188729395a40a5ed\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hi9quqcg/wheels/f9/4d/f5/0dd60e5d14063e5b09aab0c3d928b974fb854779603d92d408\n",
            "Successfully built en-core-web-sm\n",
            "Installing collected packages: pip, en-core-web-sm\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.2.1\n",
            "    Uninstalling pip-21.2.1:\n",
            "      Successfully uninstalled pip-21.2.1\n",
            "Successfully installed en-core-web-sm-1.2.0 pip-9.0.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "\n",
            "    /usr/local/envs/heptabot/lib/python3.6/site-packages/en_core_web_sm/en_core_web_sm-1.2.0\n",
            "    --> /usr/local/envs/heptabot/lib/python3.6/site-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en').\n",
            "\n",
            "\n",
            "Downloading models\n",
            "distilbert_stsb_mod 100%[===================>] 233.38M  89.4MB/s    in 2.6s    \n",
            "err_type_classifier 100%[===================>]  56.24M   117MB/s    in 0.5s    \n",
            "sentencepiece.model 100%[===================>] 773.10K  --.-KB/s    in 0.007s  \n",
            "tokenizer.json      100%[===================>]   1.32M  --.-KB/s    in 0.01s   \n",
            "\n",
            "heptabot is ready to use!\n",
            "\n",
            "real\t5m18.584s\n",
            "user\t2m58.898s\n",
            "sys\t0m43.006s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR9gSsJS4Ed4"
      },
      "source": [
        "!mkdir output\n",
        "!cp -r static output\n",
        "!mkdir raw"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N7JEiqs68jS"
      },
      "source": [
        "import subprocess\n",
        "from time import sleep\n",
        "\n",
        "_ram_before = !awk '/MemAvailable/ { printf \"%.3f\\n\", $2/1024/1024 }' /proc/meminfo\n",
        "os.environ[\"RAM_BEFORE\"] = str(_ram_before[0])\n",
        "subprocess.Popen([\"/bin/bash\", os.path.join(os.path.realpath(\".\"), \"colab_run.sh\")])\n",
        "sleep(70)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3EpipTbNRTC"
      },
      "source": [
        "import re\n",
        "import os\n",
        "import pickle\n",
        "import IPython\n",
        "from google.colab.files import download"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXiJE0RMRtxM"
      },
      "source": [
        "## Check the installation\n",
        "\n",
        "The following cell is designed to check if the preparations went through correctly. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssoqQaelSRUZ",
        "cellView": "form",
        "outputId": "3b5f3935-1501-49ed-943c-b7cf0c716172"
      },
      "source": [
        "#@markdown ### Environment check\n",
        "\n",
        "test = !lsof | grep 9090\n",
        "if len(test) > 6:\n",
        "  print('\\x1b[1mEverything seems to be OK!\\x1b[0m')\n",
        "else:\n",
        "  print('\\x1b[1;31mSeems like something went wrong.\\nTry waiting for a couple minutes and re-run this cell. If the problem persists, click Runtime ‚ûî Factory reset runtime ‚ûî YES and redo all the steps.\\x1b[0m')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mEverything seems to be OK!\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzdqmwWb-iGy"
      },
      "source": [
        "## Get the texts\n",
        "\n",
        "The textual data is downloaded in this part. Here we use 3 essays from [REALEC](https://realec.org/) as example data; you should, however, change this part to process the texts you need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwJuULSeGVrY"
      },
      "source": [
        "!mkdir input\n",
        "\n",
        "!wget -q \"https://realec.org/ajax.cgi?action=downloadFile&collection=%2Fexam%2FExam2015%2F&document=2015_KT_12_2&extension=txt&protocol=1\" -O ./input/KT_12_2.txt\n",
        "!wget -q \"https://realec.org/ajax.cgi?action=downloadFile&collection=%2Fexam%2FExam2014%2F&document=2014_ESha_2_1&extension=txt&protocol=1\" -O ./input/ESha_2_1.txt\n",
        "!wget -q \"https://realec.org/ajax.cgi?action=downloadFile&collection=%2Fexam%2FExam2016%2F&document=2016_LKa_2_2&extension=txt&protocol=1\" -O ./input/LKa_2_2.txt\n",
        "\n",
        "files = [\"KT_12_2.txt\", \"ESha_2_1.txt\", \"LKa_2_2.txt\"]\n",
        "textdict = {}\n",
        "\n",
        "for f in files:\n",
        "  with open(os.path.join(\"input\", f), \"r\", encoding=\"utf-8\") as infile:\n",
        "    textdict[f[:-4]] = infile.read()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ-zfEsWu74t"
      },
      "source": [
        "**Important**: If you got here from the error page on `heptabot` website stating \"*In order to maintain server resources and stable uptime, we limit the amounts of data that can be processed via our Web interface*\", uncomment the following code (remove all the number signs) and upload the `generated.txt` file you got from our website:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arLuNcdfurgo"
      },
      "source": [
        "#from google.colab import files\n",
        "#files.upload()\n",
        "\n",
        "#textdict = {}\n",
        "\n",
        "#with open(\"generated.txt\", \"r\", encoding=\"utf-8\") as infile:\n",
        "  #textdict[\"generated\"] = infile.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIsM9kc5hdbB"
      },
      "source": [
        "In other cases, we recommend to put your files into the **`input`** folder for comprehensibility."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B3PrPIsFXlD"
      },
      "source": [
        "Put all your texts in a `dict` with the name `textdict`, where keys are `str`'s with texts IDs (preferrably filenames without extension), while the actual data is stored also as `txt`'s in values, as such:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyyuRVhfFXH9"
      },
      "source": [
        "assert all(type(k) is str for k in textdict.keys())\n",
        "assert all(type(v) is str for v in textdict.values())"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU9bIesEGctJ"
      },
      "source": [
        "## Process data with `heptabot`\n",
        "\n",
        "The actual `heptabot` magic is performed here!\n",
        "\n",
        "**Important**: please choose the appropriate task type in the following cell. While `correction`, the default, is used to correct whole essays and only its pipeline incororates the error classification subroutine, you may also want to perform sentencewise correction. In this case, choose one of the identifiers of the relevant GEC tasks: `jfleg` (trained on JFLEG data) is for general sentencewise correction and should provide more diverse results, while `conll` (trained on CONLL-14 competition) and `bea` (trained on BEA-2019 competition) correct mainly grammar-related errors, for which case the grammar parsing data is appended to the sentence in the corresponding pipeline. Please note that `heptabot` expects whole paragraphs of text as data for `correction` and sentence-by-sentence structured data for other tasks, so make sure your file(s) contain single sentences separated by newlines if you wish to perform any other task than `correction`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59_4XO_DFghu",
        "cellView": "form"
      },
      "source": [
        "task_type = \"correction\"  #@param [\"correction\", \"jfleg\", \"conll\", \"bea\"] "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrzRsNNBKXxj",
        "outputId": "5afba316-8cc1-4015-99e8-d2da1c30b342"
      },
      "source": [
        "import random\n",
        "chosen_one = random.choice(list(textdict.keys()))\n",
        "\n",
        "print(textdict[chosen_one])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In modern world our life is demanding more and more different knowledge and skills from us so to set it children from early age go to some lessons and courses. Because of it they usually spend quite a little time outside and do not aware of all value and beauty of our nature, I can partly asree with this statement. \n",
            "From one side, it is true that nowdays children spent less time outside enjoying some simple things such as trees, grass, sun and fresh air. Even when they go for a walk, in big sities it is complicated to find place where virgin nature is saved. They have to walk around blocks of flats and roads where no fresh air or spectacular views are left, although they are very important. \n",
            "From other side, there is a lot of time children have to spend learning nature. They all have holidays when parents try to send they to different camps in forests or round the sea, to countryside where a lot of them have relatives or friends and so on. \n",
            "So in this time children have enough space and hours to learn more about nature, to learn to understand and appreciate it, to see how many it can give us and enjoy all of its advantages. \n",
            "To sum up, it is harder for children to spend a lot of time outside learning the nature now than it was before because of crazy life rhythm but there are quite a lot of possibilities to do it if they want.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRNwdsBS3wGf"
      },
      "source": [
        "texts = {}\n",
        "\n",
        "for textid in textdict:\n",
        "  texts[textid] = {\"task_type\": task_type, \"text\": textdict[textid]}\n",
        "\n",
        "with open(\"./raw/process_texts.pkl\", \"wb\") as outpickle:\n",
        "  pickle.dump(texts, outpickle)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3rkI1AuPNJM"
      },
      "source": [
        "In order to get the advantage of using TPU, we split our process in three parts. First, we prepare our texts by splitting them into batches required by `heptabot`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhS35WWpVQco",
        "outputId": "f95c3867-050b-4045-df71-fd8fca0f1c00"
      },
      "source": [
        "%%bash\n",
        "source activate heptabot\n",
        "python batchify_input.py"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing texts for TPU model inference\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]\r100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 196.69it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_tJM4a4VQsk"
      },
      "source": [
        "Then we call the TPU process (this is where our `medium` model runs inference on the texts). Please note that `mesh-tensorflow` TPU processes are prone to produce lots of logging output. We decided to omit it from this GitHub notebook but keep the output on in the actual code cell so that you can check that the process is running as intended. There is, however, an option to discard this output entirely: for this, set `SUPPRESS_OUTPUT` variable to `True` and wait for the cell below to finish the execution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxFdL5OqKyOy",
        "outputId": "b0cc76ba-f165-41d3-fbdb-d91f748e9286",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "SUPPRESS_OUTPUT = False  #@param {\"type\": \"boolean\"}\n",
        "\n",
        "if SUPPRESS_OUTPUT:\n",
        "  !bash tpu_run.sh 1>/dev/null 2>%1\n",
        "else:\n",
        "  !bash tpu_run.sh"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "I0730 21:46:02.370088 140202429888384 mesh_transformer_main.py:163] No write access to model directory. Skipping command logging.\n",
            "I0730 21:46:02.378151 140202429888384 resource_reader.py:50] system_path_file_exists:gs://heptabot/models/medium/tpu/operative_config.gin\n",
            "E0730 21:46:02.378844 140202429888384 resource_reader.py:55] Path not found: gs://heptabot/models/medium/tpu/operative_config.gin\n",
            "INFO:tensorflow:model_type=bitransformer\n",
            "I0730 21:46:02.590454 140202429888384 utils.py:2535] model_type=bitransformer\n",
            "INFO:tensorflow:mode=infer\n",
            "I0730 21:46:02.590665 140202429888384 utils.py:2536] mode=infer\n",
            "INFO:tensorflow:sequence_length={'inputs': 512, 'targets': 512}\n",
            "I0730 21:46:02.590729 140202429888384 utils.py:2537] sequence_length={'inputs': 512, 'targets': 512}\n",
            "INFO:tensorflow:batch_size=16\n",
            "I0730 21:46:02.590778 140202429888384 utils.py:2538] batch_size=16\n",
            "INFO:tensorflow:train_steps=8388608\n",
            "I0730 21:46:02.590823 140202429888384 utils.py:2539] train_steps=8388608\n",
            "INFO:tensorflow:total_run_steps=8388608\n",
            "I0730 21:46:02.590866 140202429888384 utils.py:2541] total_run_steps=8388608\n",
            "INFO:tensorflow:mesh_shape=Shape[batch=8]\n",
            "I0730 21:46:02.590915 140202429888384 utils.py:2542] mesh_shape=Shape[batch=8]\n",
            "INFO:tensorflow:layout_rules=ensemble:ensemble,batch:batch,d_ff:model,heads:model,vocab:model,experts:batch\n",
            "I0730 21:46:02.590959 140202429888384 utils.py:2543] layout_rules=ensemble:ensemble,batch:batch,d_ff:model,heads:model,vocab:model,experts:batch\n",
            "INFO:tensorflow:Building TPUConfig with tpu_job_name=None\n",
            "I0730 21:46:02.591059 140202429888384 utils.py:2558] Building TPUConfig with tpu_job_name=None\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://heptabot/models/medium/tpu', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.125.69.50:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.125.69.50:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.125.69.50:8470', '_evaluation_master': 'grpc://10.125.69.50:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f8309f15210>}\n",
            "I0730 21:46:02.694758 140202429888384 estimator.py:191] Using config: {'_model_dir': 'gs://heptabot/models/medium/tpu', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.125.69.50:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.125.69.50:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.125.69.50:8470', '_evaluation_master': 'grpc://10.125.69.50:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f8309f15210>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "I0730 21:46:02.695221 140202429888384 tpu_context.py:271] _TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.125.69.50:8470) for TPU system metadata.\n",
            "I0730 21:46:02.768779 140202429888384 tpu_system_metadata.py:91] Querying Tensorflow master (grpc://10.125.69.50:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.125.69.50:8470) to fetch topology for model parallelism. This might take a while.\n",
            "I0730 21:46:02.786120 140202429888384 tpu_system_metadata.py:176] Initializing TPU system (master: grpc://10.125.69.50:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "I0730 21:47:02.512859 140202429888384 tpu_system_metadata.py:159] Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "I0730 21:47:02.513187 140202429888384 tpu_system_metadata.py:160] *** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "I0730 21:47:02.513276 140202429888384 tpu_system_metadata.py:161] *** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "I0730 21:47:02.513379 140202429888384 tpu_system_metadata.py:163] *** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 655657826601178449)\n",
            "I0730 21:47:02.513461 140202429888384 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 655657826601178449)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 4785107481472334188)\n",
            "I0730 21:47:02.513806 140202429888384 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 4785107481472334188)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1787705276357428412)\n",
            "I0730 21:47:02.513861 140202429888384 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1787705276357428412)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 8926793066688749100)\n",
            "I0730 21:47:02.513910 140202429888384 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 8926793066688749100)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 4946127802443826845)\n",
            "I0730 21:47:02.513957 140202429888384 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 4946127802443826845)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, -8229773611882769399)\n",
            "I0730 21:47:02.514003 140202429888384 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, -8229773611882769399)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 8176823439579636433)\n",
            "I0730 21:47:02.514083 140202429888384 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 8176823439579636433)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, -1139579025962705084)\n",
            "I0730 21:47:02.514170 140202429888384 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, -1139579025962705084)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8954727879565218818)\n",
            "I0730 21:47:02.514260 140202429888384 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8954727879565218818)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 1364068133602882083)\n",
            "I0730 21:47:02.514355 140202429888384 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 1364068133602882083)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 4451903776125645674)\n",
            "I0730 21:47:02.514440 140202429888384 tpu_system_metadata.py:165] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 4451903776125645674)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0730 21:47:02.516229 140202429888384 estimator.py:1162] Calling model_fn.\n",
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "I0730 21:47:03.451906 140202429888384 tpu_context.py:357] num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "I0730 21:47:03.452190 140202429888384 tpu_context.py:359] computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "I0730 21:47:03.452308 140202429888384 tpu_context.py:360] num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "I0730 21:47:03.452648 140202429888384 tpu_context.py:363] device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "I0730 21:47:03.452963 140202429888384 tpu_context.py:365] device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "I0730 21:47:03.510826 140202429888384 simd_mesh_impl.py:860] auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "I0730 21:47:03.511080 140202429888384 simd_mesh_impl.py:938] auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "W0730 21:47:03.511283 140202429888384 simd_mesh_impl.py:65] SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('vocab', 'model'), ('batch', 'batch'), ('heads', 'model'), ('d_ff', 'model'), ('ensemble', 'ensemble')}\n",
            "I0730 21:47:03.511422 140202429888384 simd_mesh_impl.py:67] SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('vocab', 'model'), ('batch', 'batch'), ('heads', 'model'), ('d_ff', 'model'), ('ensemble', 'ensemble')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f82aac48290>\n",
            "I0730 21:47:03.511511 140202429888384 simd_mesh_impl.py:68] Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f82aac48290>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "W0730 21:47:03.557936 140202429888384 ops.py:4197] Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "W0730 21:47:04.257187 140202429888384 ops.py:4197] Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "W0730 21:47:05.517856 140202429888384 ops.py:4197] Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "I0730 21:47:05.708572 140202429888384 simd_mesh_impl.py:91] Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "I0730 21:47:21.724500 140202429888384 simd_mesh_impl.py:340] Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "I0730 21:47:21.741704 140202429888384 simd_mesh_impl.py:340] Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.746564 140202429888384 ops.py:5949] Variable decoder/block_000/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.746846 140202429888384 ops.py:5949] Variable decoder/block_000/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.746975 140202429888384 ops.py:5949] Variable decoder/block_000/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.747088 140202429888384 ops.py:5949] Variable decoder/block_000/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.747208 140202429888384 ops.py:5949] Variable decoder/block_000/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.747333 140202429888384 ops.py:5949] Variable decoder/block_000/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.747445 140202429888384 ops.py:5949] Variable decoder/block_000/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.747552 140202429888384 ops.py:5949] Variable decoder/block_000/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "I0730 21:47:21.747669 140202429888384 ops.py:5949] Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "I0730 21:47:21.747776 140202429888384 ops.py:5949] Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.747911 140202429888384 ops.py:5949] Variable decoder/block_001/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.748054 140202429888384 ops.py:5949] Variable decoder/block_001/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.748165 140202429888384 ops.py:5949] Variable decoder/block_001/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.748275 140202429888384 ops.py:5949] Variable decoder/block_001/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.748397 140202429888384 ops.py:5949] Variable decoder/block_001/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.748505 140202429888384 ops.py:5949] Variable decoder/block_001/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.748624 140202429888384 ops.py:5949] Variable decoder/block_001/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.748731 140202429888384 ops.py:5949] Variable decoder/block_001/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "I0730 21:47:21.748840 140202429888384 ops.py:5949] Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "I0730 21:47:21.748946 140202429888384 ops.py:5949] Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.749054 140202429888384 ops.py:5949] Variable decoder/block_002/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.749162 140202429888384 ops.py:5949] Variable decoder/block_002/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.749268 140202429888384 ops.py:5949] Variable decoder/block_002/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.749388 140202429888384 ops.py:5949] Variable decoder/block_002/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.749497 140202429888384 ops.py:5949] Variable decoder/block_002/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.749611 140202429888384 ops.py:5949] Variable decoder/block_002/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.749718 140202429888384 ops.py:5949] Variable decoder/block_002/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.749825 140202429888384 ops.py:5949] Variable decoder/block_002/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "I0730 21:47:21.749933 140202429888384 ops.py:5949] Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "I0730 21:47:21.750040 140202429888384 ops.py:5949] Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.750151 140202429888384 ops.py:5949] Variable decoder/block_003/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.750260 140202429888384 ops.py:5949] Variable decoder/block_003/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.750380 140202429888384 ops.py:5949] Variable decoder/block_003/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.750487 140202429888384 ops.py:5949] Variable decoder/block_003/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.750599 140202429888384 ops.py:5949] Variable decoder/block_003/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.750708 140202429888384 ops.py:5949] Variable decoder/block_003/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.750816 140202429888384 ops.py:5949] Variable decoder/block_003/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.750922 140202429888384 ops.py:5949] Variable decoder/block_003/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "I0730 21:47:21.751030 140202429888384 ops.py:5949] Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "I0730 21:47:21.751137 140202429888384 ops.py:5949] Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.751245 140202429888384 ops.py:5949] Variable decoder/block_004/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.812644 140202429888384 ops.py:5949] Variable decoder/block_004/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.812911 140202429888384 ops.py:5949] Variable decoder/block_004/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.813092 140202429888384 ops.py:5949] Variable decoder/block_004/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.813252 140202429888384 ops.py:5949] Variable decoder/block_004/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.813416 140202429888384 ops.py:5949] Variable decoder/block_004/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.813562 140202429888384 ops.py:5949] Variable decoder/block_004/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.813730 140202429888384 ops.py:5949] Variable decoder/block_004/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "I0730 21:47:21.813891 140202429888384 ops.py:5949] Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "I0730 21:47:21.814052 140202429888384 ops.py:5949] Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.814206 140202429888384 ops.py:5949] Variable decoder/block_005/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.814383 140202429888384 ops.py:5949] Variable decoder/block_005/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.814566 140202429888384 ops.py:5949] Variable decoder/block_005/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.814743 140202429888384 ops.py:5949] Variable decoder/block_005/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.814906 140202429888384 ops.py:5949] Variable decoder/block_005/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.815060 140202429888384 ops.py:5949] Variable decoder/block_005/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.815228 140202429888384 ops.py:5949] Variable decoder/block_005/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.815402 140202429888384 ops.py:5949] Variable decoder/block_005/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "I0730 21:47:21.815572 140202429888384 ops.py:5949] Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "I0730 21:47:21.815752 140202429888384 ops.py:5949] Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.815914 140202429888384 ops.py:5949] Variable decoder/block_006/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.816077 140202429888384 ops.py:5949] Variable decoder/block_006/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.816235 140202429888384 ops.py:5949] Variable decoder/block_006/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.816409 140202429888384 ops.py:5949] Variable decoder/block_006/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.816570 140202429888384 ops.py:5949] Variable decoder/block_006/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.816839 140202429888384 ops.py:5949] Variable decoder/block_006/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.817126 140202429888384 ops.py:5949] Variable decoder/block_006/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.817341 140202429888384 ops.py:5949] Variable decoder/block_006/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "I0730 21:47:21.817521 140202429888384 ops.py:5949] Variable decoder/block_006/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_006/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "I0730 21:47:21.817695 140202429888384 ops.py:5949] Variable decoder/block_006/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.817869 140202429888384 ops.py:5949] Variable decoder/block_007/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.818038 140202429888384 ops.py:5949] Variable decoder/block_007/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.818261 140202429888384 ops.py:5949] Variable decoder/block_007/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.818462 140202429888384 ops.py:5949] Variable decoder/block_007/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.818638 140202429888384 ops.py:5949] Variable decoder/block_007/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.818821 140202429888384 ops.py:5949] Variable decoder/block_007/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.818988 140202429888384 ops.py:5949] Variable decoder/block_007/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.819145 140202429888384 ops.py:5949] Variable decoder/block_007/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "I0730 21:47:21.819335 140202429888384 ops.py:5949] Variable decoder/block_007/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_007/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "I0730 21:47:21.819506 140202429888384 ops.py:5949] Variable decoder/block_007/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.819673 140202429888384 ops.py:5949] Variable decoder/block_008/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.819842 140202429888384 ops.py:5949] Variable decoder/block_008/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.820003 140202429888384 ops.py:5949] Variable decoder/block_008/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.820166 140202429888384 ops.py:5949] Variable decoder/block_008/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.820356 140202429888384 ops.py:5949] Variable decoder/block_008/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.820524 140202429888384 ops.py:5949] Variable decoder/block_008/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.820685 140202429888384 ops.py:5949] Variable decoder/block_008/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.820845 140202429888384 ops.py:5949] Variable decoder/block_008/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "I0730 21:47:21.821008 140202429888384 ops.py:5949] Variable decoder/block_008/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_008/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "I0730 21:47:21.821168 140202429888384 ops.py:5949] Variable decoder/block_008/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.821356 140202429888384 ops.py:5949] Variable decoder/block_009/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.821525 140202429888384 ops.py:5949] Variable decoder/block_009/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.821686 140202429888384 ops.py:5949] Variable decoder/block_009/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.821850 140202429888384 ops.py:5949] Variable decoder/block_009/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.822008 140202429888384 ops.py:5949] Variable decoder/block_009/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.822168 140202429888384 ops.py:5949] Variable decoder/block_009/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.822359 140202429888384 ops.py:5949] Variable decoder/block_009/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.822524 140202429888384 ops.py:5949] Variable decoder/block_009/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "I0730 21:47:21.822689 140202429888384 ops.py:5949] Variable decoder/block_009/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_009/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "I0730 21:47:21.822857 140202429888384 ops.py:5949] Variable decoder/block_009/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.823012 140202429888384 ops.py:5949] Variable decoder/block_010/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.823158 140202429888384 ops.py:5949] Variable decoder/block_010/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.823340 140202429888384 ops.py:5949] Variable decoder/block_010/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.823503 140202429888384 ops.py:5949] Variable decoder/block_010/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.823664 140202429888384 ops.py:5949] Variable decoder/block_010/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.823823 140202429888384 ops.py:5949] Variable decoder/block_010/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.823986 140202429888384 ops.py:5949] Variable decoder/block_010/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.824144 140202429888384 ops.py:5949] Variable decoder/block_010/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "I0730 21:47:21.824327 140202429888384 ops.py:5949] Variable decoder/block_010/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_010/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "I0730 21:47:21.824494 140202429888384 ops.py:5949] Variable decoder/block_010/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.824653 140202429888384 ops.py:5949] Variable decoder/block_011/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.824817 140202429888384 ops.py:5949] Variable decoder/block_011/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.824976 140202429888384 ops.py:5949] Variable decoder/block_011/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.825133 140202429888384 ops.py:5949] Variable decoder/block_011/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.825325 140202429888384 ops.py:5949] Variable decoder/block_011/layer_001/EncDecAttention/k                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.825490 140202429888384 ops.py:5949] Variable decoder/block_011/layer_001/EncDecAttention/o                size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.825662 140202429888384 ops.py:5949] Variable decoder/block_011/layer_001/EncDecAttention/q                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.825828 140202429888384 ops.py:5949] Variable decoder/block_011/layer_001/EncDecAttention/v                size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "I0730 21:47:21.825995 140202429888384 ops.py:5949] Variable decoder/block_011/layer_002/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable decoder/block_011/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "I0730 21:47:21.826156 140202429888384 ops.py:5949] Variable decoder/block_011/layer_002/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.826343 140202429888384 ops.py:5949] Variable encoder/block_000/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.826522 140202429888384 ops.py:5949] Variable encoder/block_000/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.826680 140202429888384 ops.py:5949] Variable encoder/block_000/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.826822 140202429888384 ops.py:5949] Variable encoder/block_000/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "I0730 21:47:21.826959 140202429888384 ops.py:5949] Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "I0730 21:47:21.827123 140202429888384 ops.py:5949] Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.827297 140202429888384 ops.py:5949] Variable encoder/block_001/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.827475 140202429888384 ops.py:5949] Variable encoder/block_001/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.827636 140202429888384 ops.py:5949] Variable encoder/block_001/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.827792 140202429888384 ops.py:5949] Variable encoder/block_001/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "I0730 21:47:21.827987 140202429888384 ops.py:5949] Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "I0730 21:47:21.828197 140202429888384 ops.py:5949] Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.828384 140202429888384 ops.py:5949] Variable encoder/block_002/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.828558 140202429888384 ops.py:5949] Variable encoder/block_002/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.828718 140202429888384 ops.py:5949] Variable encoder/block_002/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.828879 140202429888384 ops.py:5949] Variable encoder/block_002/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "I0730 21:47:21.829036 140202429888384 ops.py:5949] Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "I0730 21:47:21.829202 140202429888384 ops.py:5949] Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.829381 140202429888384 ops.py:5949] Variable encoder/block_003/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.829542 140202429888384 ops.py:5949] Variable encoder/block_003/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.829704 140202429888384 ops.py:5949] Variable encoder/block_003/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.829882 140202429888384 ops.py:5949] Variable encoder/block_003/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "I0730 21:47:21.830047 140202429888384 ops.py:5949] Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "I0730 21:47:21.830219 140202429888384 ops.py:5949] Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.830395 140202429888384 ops.py:5949] Variable encoder/block_004/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.830557 140202429888384 ops.py:5949] Variable encoder/block_004/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.830713 140202429888384 ops.py:5949] Variable encoder/block_004/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.830873 140202429888384 ops.py:5949] Variable encoder/block_004/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "I0730 21:47:21.831031 140202429888384 ops.py:5949] Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "I0730 21:47:21.831192 140202429888384 ops.py:5949] Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.831371 140202429888384 ops.py:5949] Variable encoder/block_005/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.831538 140202429888384 ops.py:5949] Variable encoder/block_005/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.831701 140202429888384 ops.py:5949] Variable encoder/block_005/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.831872 140202429888384 ops.py:5949] Variable encoder/block_005/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "I0730 21:47:21.832040 140202429888384 ops.py:5949] Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "I0730 21:47:21.832212 140202429888384 ops.py:5949] Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.832382 140202429888384 ops.py:5949] Variable encoder/block_006/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.832545 140202429888384 ops.py:5949] Variable encoder/block_006/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.832699 140202429888384 ops.py:5949] Variable encoder/block_006/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.832854 140202429888384 ops.py:5949] Variable encoder/block_006/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "I0730 21:47:21.833015 140202429888384 ops.py:5949] Variable encoder/block_006/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_006/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "I0730 21:47:21.833167 140202429888384 ops.py:5949] Variable encoder/block_006/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.833353 140202429888384 ops.py:5949] Variable encoder/block_007/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.833515 140202429888384 ops.py:5949] Variable encoder/block_007/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.833669 140202429888384 ops.py:5949] Variable encoder/block_007/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.833828 140202429888384 ops.py:5949] Variable encoder/block_007/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "I0730 21:47:21.833984 140202429888384 ops.py:5949] Variable encoder/block_007/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_007/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "I0730 21:47:21.834141 140202429888384 ops.py:5949] Variable encoder/block_007/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.834308 140202429888384 ops.py:5949] Variable encoder/block_008/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.834484 140202429888384 ops.py:5949] Variable encoder/block_008/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.834642 140202429888384 ops.py:5949] Variable encoder/block_008/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.834798 140202429888384 ops.py:5949] Variable encoder/block_008/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "I0730 21:47:21.834959 140202429888384 ops.py:5949] Variable encoder/block_008/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_008/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "I0730 21:47:21.835114 140202429888384 ops.py:5949] Variable encoder/block_008/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.835288 140202429888384 ops.py:5949] Variable encoder/block_009/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.835464 140202429888384 ops.py:5949] Variable encoder/block_009/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.835619 140202429888384 ops.py:5949] Variable encoder/block_009/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.835780 140202429888384 ops.py:5949] Variable encoder/block_009/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "I0730 21:47:21.835937 140202429888384 ops.py:5949] Variable encoder/block_009/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_009/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "I0730 21:47:21.836089 140202429888384 ops.py:5949] Variable encoder/block_009/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.836259 140202429888384 ops.py:5949] Variable encoder/block_010/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.836432 140202429888384 ops.py:5949] Variable encoder/block_010/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.836592 140202429888384 ops.py:5949] Variable encoder/block_010/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.836748 140202429888384 ops.py:5949] Variable encoder/block_010/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "I0730 21:47:21.836902 140202429888384 ops.py:5949] Variable encoder/block_010/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_010/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "I0730 21:47:21.837052 140202429888384 ops.py:5949] Variable encoder/block_010/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.837216 140202429888384 ops.py:5949] Variable encoder/block_011/layer_000/SelfAttention/k                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "I0730 21:47:21.837394 140202429888384 ops.py:5949] Variable encoder/block_011/layer_000/SelfAttention/o                  size 589824       slice_size 589824       Shape[heads=768, d_model=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.837553 140202429888384 ops.py:5949] Variable encoder/block_011/layer_000/SelfAttention/q                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "I0730 21:47:21.837711 140202429888384 ops.py:5949] Variable encoder/block_011/layer_000/SelfAttention/v                  size 589824       slice_size 589824       Shape[d_model=768, heads=768]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "I0730 21:47:21.837868 140202429888384 ops.py:5949] Variable encoder/block_011/layer_001/DenseReluDense/wi/kernel         size 2359296      slice_size 2359296      Shape[d_model=768, d_ff=3072]                               \n",
            "INFO:tensorflow:Variable encoder/block_011/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "I0730 21:47:21.838022 140202429888384 ops.py:5949] Variable encoder/block_011/layer_001/DenseReluDense/wo/kernel         size 2359296      slice_size 2359296      Shape[d_ff=3072, d_model=768]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 24674304     slice_size 24674304     Shape[vocab=32128, d_model=768]                             \n",
            "I0730 21:47:21.838196 140202429888384 ops.py:5949] Variable shared/embedding                                             size 24674304     slice_size 24674304     Shape[vocab=32128, d_model=768]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 768          slice_size 768          Shape[stacked=2, heads=12, buckets=32]                      \n",
            "I0730 21:47:21.838390 140202429888384 ops.py:5949] Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 768          slice_size 768          Shape[stacked=2, heads=12, buckets=32]                      \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "I0730 21:47:21.838521 140202429888384 ops.py:5949]     encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "I0730 21:47:21.838628 140202429888384 ops.py:5949]     decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 47616        slice_size 47616        Shape[stacked=62, d_model=768]                              \n",
            "I0730 21:47:21.838772 140202429888384 ops.py:5949] Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 47616        slice_size 47616        Shape[stacked=62, d_model=768]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "I0730 21:47:21.838891 140202429888384 ops.py:5949]     encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "I0730 21:47:21.838993 140202429888384 ops.py:5949]     encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "I0730 21:47:21.839083 140202429888384 ops.py:5949]     encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "I0730 21:47:21.839174 140202429888384 ops.py:5949]     encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "I0730 21:47:21.839275 140202429888384 ops.py:5949]     encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "I0730 21:47:21.839381 140202429888384 ops.py:5949]     encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "I0730 21:47:21.839472 140202429888384 ops.py:5949]     encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "I0730 21:47:21.839558 140202429888384 ops.py:5949]     encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "I0730 21:47:21.839646 140202429888384 ops.py:5949]     encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "I0730 21:47:21.839733 140202429888384 ops.py:5949]     encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "I0730 21:47:21.839820 140202429888384 ops.py:5949]     encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "I0730 21:47:21.839903 140202429888384 ops.py:5949]     encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_006/layer_000/layer_norm/scale\n",
            "I0730 21:47:21.839987 140202429888384 ops.py:5949]     encoder/block_006/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_006/layer_001/layer_norm/scale\n",
            "I0730 21:47:21.840072 140202429888384 ops.py:5949]     encoder/block_006/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_007/layer_000/layer_norm/scale\n",
            "I0730 21:47:21.840158 140202429888384 ops.py:5949]     encoder/block_007/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_007/layer_001/layer_norm/scale\n",
            "I0730 21:47:21.840258 140202429888384 ops.py:5949]     encoder/block_007/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_008/layer_000/layer_norm/scale\n",
            "I0730 21:47:21.840359 140202429888384 ops.py:5949]     encoder/block_008/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_008/layer_001/layer_norm/scale\n",
            "I0730 21:47:21.840447 140202429888384 ops.py:5949]     encoder/block_008/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_009/layer_000/layer_norm/scale\n",
            "I0730 21:47:21.840548 140202429888384 ops.py:5949]     encoder/block_009/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_009/layer_001/layer_norm/scale\n",
            "I0730 21:47:21.840634 140202429888384 ops.py:5949]     encoder/block_009/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_010/layer_000/layer_norm/scale\n",
            "I0730 21:47:21.840721 140202429888384 ops.py:5949]     encoder/block_010/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_010/layer_001/layer_norm/scale\n",
            "I0730 21:47:21.840806 140202429888384 ops.py:5949]     encoder/block_010/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_011/layer_000/layer_norm/scale\n",
            "I0730 21:47:21.840889 140202429888384 ops.py:5949]     encoder/block_011/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_011/layer_001/layer_norm/scale\n",
            "I0730 21:47:21.840976 140202429888384 ops.py:5949]     encoder/block_011/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "I0730 21:47:21.841068 140202429888384 ops.py:5949]     encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "I0730 21:47:21.841151 140202429888384 ops.py:5949]     decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "I0730 21:47:21.841246 140202429888384 ops.py:5949]     decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "I0730 21:47:21.841345 140202429888384 ops.py:5949]     decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "I0730 21:47:21.841436 140202429888384 ops.py:5949]     decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "I0730 21:47:21.841521 140202429888384 ops.py:5949]     decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "I0730 21:47:21.841605 140202429888384 ops.py:5949]     decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "I0730 21:47:21.841693 140202429888384 ops.py:5949]     decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "I0730 21:47:21.841779 140202429888384 ops.py:5949]     decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "I0730 21:47:21.841865 140202429888384 ops.py:5949]     decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "I0730 21:47:21.841951 140202429888384 ops.py:5949]     decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "I0730 21:47:21.842036 140202429888384 ops.py:5949]     decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "I0730 21:47:21.842119 140202429888384 ops.py:5949]     decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "I0730 21:47:21.842214 140202429888384 ops.py:5949]     decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "I0730 21:47:21.842304 140202429888384 ops.py:5949]     decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "I0730 21:47:21.842406 140202429888384 ops.py:5949]     decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "I0730 21:47:21.842491 140202429888384 ops.py:5949]     decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "I0730 21:47:21.842576 140202429888384 ops.py:5949]     decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "I0730 21:47:21.842662 140202429888384 ops.py:5949]     decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_006/layer_000/layer_norm/scale\n",
            "I0730 21:47:21.842748 140202429888384 ops.py:5949]     decoder/block_006/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_006/layer_001/layer_norm/scale\n",
            "I0730 21:47:21.842834 140202429888384 ops.py:5949]     decoder/block_006/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_006/layer_002/layer_norm/scale\n",
            "I0730 21:47:21.842918 140202429888384 ops.py:5949]     decoder/block_006/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_007/layer_000/layer_norm/scale\n",
            "I0730 21:47:21.843003 140202429888384 ops.py:5949]     decoder/block_007/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_007/layer_001/layer_norm/scale\n",
            "I0730 21:47:21.843089 140202429888384 ops.py:5949]     decoder/block_007/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_007/layer_002/layer_norm/scale\n",
            "I0730 21:47:21.843165 140202429888384 ops.py:5949]     decoder/block_007/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_008/layer_000/layer_norm/scale\n",
            "I0730 21:47:21.843261 140202429888384 ops.py:5949]     decoder/block_008/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_008/layer_001/layer_norm/scale\n",
            "I0730 21:47:21.843362 140202429888384 ops.py:5949]     decoder/block_008/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_008/layer_002/layer_norm/scale\n",
            "I0730 21:47:21.843450 140202429888384 ops.py:5949]     decoder/block_008/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_009/layer_000/layer_norm/scale\n",
            "I0730 21:47:21.843547 140202429888384 ops.py:5949]     decoder/block_009/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_009/layer_001/layer_norm/scale\n",
            "I0730 21:47:21.843637 140202429888384 ops.py:5949]     decoder/block_009/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_009/layer_002/layer_norm/scale\n",
            "I0730 21:47:21.843726 140202429888384 ops.py:5949]     decoder/block_009/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_010/layer_000/layer_norm/scale\n",
            "I0730 21:47:21.843814 140202429888384 ops.py:5949]     decoder/block_010/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_010/layer_001/layer_norm/scale\n",
            "I0730 21:47:21.843899 140202429888384 ops.py:5949]     decoder/block_010/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_010/layer_002/layer_norm/scale\n",
            "I0730 21:47:21.843986 140202429888384 ops.py:5949]     decoder/block_010/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_011/layer_000/layer_norm/scale\n",
            "I0730 21:47:21.844070 140202429888384 ops.py:5949]     decoder/block_011/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_011/layer_001/layer_norm/scale\n",
            "I0730 21:47:21.844155 140202429888384 ops.py:5949]     decoder/block_011/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_011/layer_002/layer_norm/scale\n",
            "I0730 21:47:21.844251 140202429888384 ops.py:5949]     decoder/block_011/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "I0730 21:47:21.844351 140202429888384 ops.py:5949]     decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 195     Total size: 222903552        Total slice_size: 222903552      \n",
            "I0730 21:47:21.844460 140202429888384 ops.py:5949] Trainable Variables            count: 195     Total size: 222903552        Total slice_size: 222903552      \n",
            "INFO:tensorflow:All Variables                  count: 195     Total size: 222903552        Total slice_size: 222903552      \n",
            "I0730 21:47:21.847012 140202429888384 ops.py:5949] All Variables                  count: 195     Total size: 222903552        Total slice_size: 222903552      \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 1.31e+05\n",
            " allconcat/0: 1.31e+05\n",
            "  allconcat/0/reshape_op: 1.31e+05\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 2.49e+12\n",
            "einsum_unique: 2.47e+12\n",
            "output: 2.9e+10\n",
            " output/AddOperation: 6.85e+09\n",
            " output/BinaryOpWithBroadcasting: 1.51e+08\n",
            " output/Constant: 1.51e+08\n",
            " output/EinsumOperation: 5.87e+09\n",
            " output/ImportOperation: 6.64e+04\n",
            " output/MinMaxOperation: 7.55e+07\n",
            " output/OneHotOperation: 2.14e+09\n",
            " output/RangeOperation: 8.19e+03\n",
            " output/ReduceOperation: 7.59e+06\n",
            " output/ReshapeOperation: 1.29e+09\n",
            " output/ScalarAddOperation: 1.01e+08\n",
            " output/ScalarMultiplyOperation: 2.59e+08\n",
            " output/ShiftOperation: 8.19e+03\n",
            " output/SlicewiseOperation: 8.35e+09\n",
            " output/StackedVariable: 3.87e+05\n",
            " output/StopGradient: 1.81e+09\n",
            " output/UnstackOperation: 3.87e+05\n",
            " output/Variable: 1.78e+09\n",
            " output/WhileLoopOperation: 1.51e+08\n",
            "output_unique: 2.39e+10\n",
            " output_unique/AddOperation: 6.47e+09\n",
            " output_unique/BinaryOpWithBroadcasting: 6.32e+07\n",
            " output_unique/Constant: 1.51e+08\n",
            " output_unique/EinsumOperation: 5.23e+09\n",
            " output_unique/ImportOperation: 8.3e+03\n",
            " output_unique/MinMaxOperation: 9.45e+06\n",
            " output_unique/OneHotOperation: 7.28e+08\n",
            " output_unique/RangeOperation: 1.02e+03\n",
            " output_unique/ReduceOperation: 7.59e+06\n",
            " output_unique/ReshapeOperation: 1.29e+09\n",
            " output_unique/ScalarAddOperation: 1.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 8.24e+07\n",
            " output_unique/ShiftOperation: 8.19e+03\n",
            " output_unique/SlicewiseOperation: 7.69e+09\n",
            " output_unique/StackedVariable: 4.84e+04\n",
            " output_unique/StopGradient: 1.81e+09\n",
            " output_unique/UnstackOperation: 4.84e+04\n",
            " output_unique/Variable: 2.23e+08\n",
            " output_unique/WhileLoopOperation: 1.51e+08\n",
            "variables: 2.23e+08\n",
            " variables/trainable: 2.23e+08\n",
            "I0730 21:47:21.865619 140202429888384 ops.py:5949] Counters:\n",
            "allconcat: 1.31e+05\n",
            " allconcat/0: 1.31e+05\n",
            "  allconcat/0/reshape_op: 1.31e+05\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 2.49e+12\n",
            "einsum_unique: 2.47e+12\n",
            "output: 2.9e+10\n",
            " output/AddOperation: 6.85e+09\n",
            " output/BinaryOpWithBroadcasting: 1.51e+08\n",
            " output/Constant: 1.51e+08\n",
            " output/EinsumOperation: 5.87e+09\n",
            " output/ImportOperation: 6.64e+04\n",
            " output/MinMaxOperation: 7.55e+07\n",
            " output/OneHotOperation: 2.14e+09\n",
            " output/RangeOperation: 8.19e+03\n",
            " output/ReduceOperation: 7.59e+06\n",
            " output/ReshapeOperation: 1.29e+09\n",
            " output/ScalarAddOperation: 1.01e+08\n",
            " output/ScalarMultiplyOperation: 2.59e+08\n",
            " output/ShiftOperation: 8.19e+03\n",
            " output/SlicewiseOperation: 8.35e+09\n",
            " output/StackedVariable: 3.87e+05\n",
            " output/StopGradient: 1.81e+09\n",
            " output/UnstackOperation: 3.87e+05\n",
            " output/Variable: 1.78e+09\n",
            " output/WhileLoopOperation: 1.51e+08\n",
            "output_unique: 2.39e+10\n",
            " output_unique/AddOperation: 6.47e+09\n",
            " output_unique/BinaryOpWithBroadcasting: 6.32e+07\n",
            " output_unique/Constant: 1.51e+08\n",
            " output_unique/EinsumOperation: 5.23e+09\n",
            " output_unique/ImportOperation: 8.3e+03\n",
            " output_unique/MinMaxOperation: 9.45e+06\n",
            " output_unique/OneHotOperation: 7.28e+08\n",
            " output_unique/RangeOperation: 1.02e+03\n",
            " output_unique/ReduceOperation: 7.59e+06\n",
            " output_unique/ReshapeOperation: 1.29e+09\n",
            " output_unique/ScalarAddOperation: 1.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 8.24e+07\n",
            " output_unique/ShiftOperation: 8.19e+03\n",
            " output_unique/SlicewiseOperation: 7.69e+09\n",
            " output_unique/StackedVariable: 4.84e+04\n",
            " output_unique/StopGradient: 1.81e+09\n",
            " output_unique/UnstackOperation: 4.84e+04\n",
            " output_unique/Variable: 2.23e+08\n",
            " output_unique/WhileLoopOperation: 1.51e+08\n",
            "variables: 2.23e+08\n",
            " variables/trainable: 2.23e+08\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0730 21:47:22.123977 140202429888384 estimator.py:1164] Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "I0730 21:47:22.128798 140202429888384 tpu_estimator.py:514] TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0730 21:47:22.601644 140202429888384 monitored_session.py:247] Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://heptabot/models/medium/tpu/model.ckpt-1003800\n",
            "I0730 21:47:22.648501 140202429888384 saver.py:1298] Restoring parameters from gs://heptabot/models/medium/tpu/model.ckpt-1003800\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0730 21:47:31.898455 140202429888384 session_manager.py:531] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0730 21:47:32.765995 140202429888384 session_manager.py:534] Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:840: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "W0730 21:47:33.118833 140202429888384 deprecation.py:336] From /usr/local/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:840: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "I0730 21:47:33.147228 140199045883648 tpu_estimator.py:531] Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "I0730 21:47:33.147569 140199037490944 tpu_estimator.py:551] Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "I0730 21:47:33.189471 140202429888384 util.py:96] Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "I0730 21:47:33.189773 140202429888384 ops.py:5777] Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "I0730 21:47:33.987099 140202429888384 ops.py:5779] Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "I0730 21:47:34.313001 140202429888384 tpu_estimator.py:617] Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0730 21:47:34.313541 140202429888384 tpu_estimator.py:621] Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "I0730 21:47:34.314498 140199037490944 tpu_estimator.py:289] Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: correction: In modern world our life is demanding more and more different knowledge and skills from us so to set it children from early age go to some lessons and courses. Because of it they usually spend quite a little time outside and do not aware of all value and beauty of our nature, I can partly asree with this statement.  ‚Åá br> From one side, it is true that nowdays children spent less time outside enjoying some simple things such as trees, grass, sun and fresh air. Even when they go for a walk, in big sities it is complicated to find place where virgin nature is saved. They have to walk around blocks of flats and roads where no fresh air or spectacular views are left, although they are very important.  ‚Åá br> From other side, there is a lot of time children have to spend learning nature. They all have holidays when parents try to send they to different camps in forests or round the sea, to countryside where a lot of them have relatives or friends and so on.  ‚Åá br> So in this time children have enough space and hours to learn more about nature, to learn to understand and appreciate it, to see how many it can give us and enjoy all of its advantages.  ‚Åá br> To sum up, it is harder for children to spend a lot of time outside learning the nature now than it was before because of crazy life rhythm but there are quite a lot of possibilities to do it if they want.  ‚Åá br>\n",
            "I0730 21:47:47.588631 140202429888384 utils.py:1122] decoded 0: correction: In modern world our life is demanding more and more different knowledge and skills from us so to set it children from early age go to some lessons and courses. Because of it they usually spend quite a little time outside and do not aware of all value and beauty of our nature, I can partly asree with this statement.  ‚Åá br> From one side, it is true that nowdays children spent less time outside enjoying some simple things such as trees, grass, sun and fresh air. Even when they go for a walk, in big sities it is complicated to find place where virgin nature is saved. They have to walk around blocks of flats and roads where no fresh air or spectacular views are left, although they are very important.  ‚Åá br> From other side, there is a lot of time children have to spend learning nature. They all have holidays when parents try to send they to different camps in forests or round the sea, to countryside where a lot of them have relatives or friends and so on.  ‚Åá br> So in this time children have enough space and hours to learn more about nature, to learn to understand and appreciate it, to see how many it can give us and enjoy all of its advantages.  ‚Åá br> To sum up, it is harder for children to spend a lot of time outside learning the nature now than it was before because of crazy life rhythm but there are quite a lot of possibilities to do it if they want.  ‚Åá br>\n",
            "INFO:tensorflow:            -> In the modern world our life is demanding more and more different knowledge and skills from us so to set it, children from an early age go to some lessons and courses. Because of this, they usually spend quite a little time outside and are not aware of all the value and beauty of our nature. I can partly agree with this statement.  ‚Åá br> On the one hand, it is true that nowadays children spend less time outside enjoying some simple things such as trees, grass, the sun and fresh air. Even when they go for a walk, in big cities it is complicated to find a place where virgin nature is saved. They have to walk around blocks of flats and roads where no fresh air or spectacular views are left, although they are very important.  ‚Åá br> On the other hand, there is a lot of time children have to spend learning about nature. They all have holidays when parents try to send them to different camps in forests or around the sea, to countryside where a lot of them have relatives or friends and so on.  ‚Åá br> So, at this time, children have enough space and hours to learn more about nature, to learn to understand and appreciate it, to see how much it can give us and enjoy all of its advantages.  ‚Åá br> To sum up, it is harder for children to spend a lot of time outside learning about nature now than it was before because of the crazy life rhythm but there are quite a lot of possibilities to do it if they want.  ‚Åá br>\n",
            "I0730 21:47:47.588927 140202429888384 utils.py:1123]             -> In the modern world our life is demanding more and more different knowledge and skills from us so to set it, children from an early age go to some lessons and courses. Because of this, they usually spend quite a little time outside and are not aware of all the value and beauty of our nature. I can partly agree with this statement.  ‚Åá br> On the one hand, it is true that nowadays children spend less time outside enjoying some simple things such as trees, grass, the sun and fresh air. Even when they go for a walk, in big cities it is complicated to find a place where virgin nature is saved. They have to walk around blocks of flats and roads where no fresh air or spectacular views are left, although they are very important.  ‚Åá br> On the other hand, there is a lot of time children have to spend learning about nature. They all have holidays when parents try to send them to different camps in forests or around the sea, to countryside where a lot of them have relatives or friends and so on.  ‚Åá br> So, at this time, children have enough space and hours to learn more about nature, to learn to understand and appreciate it, to see how much it can give us and enjoy all of its advantages.  ‚Åá br> To sum up, it is harder for children to spend a lot of time outside learning about nature now than it was before because of the crazy life rhythm but there are quite a lot of possibilities to do it if they want.  ‚Åá br>\n",
            "INFO:tensorflow:decoded 1: correction: The bar chart illustrates information about the percentage between men and women at levels of post-school skills in Australia in the duration of 1999.  ‚Åá br> It is noticable that the figures in males who skilled vocational diploma was the highest and made up about 90%. The lowest persantage in men was the undergraduate diploma and came to approximately 35%. In terms of Bachelor's degree, postgraduate diploma and Master's degree in males the figures fell on 47%, 70% and 60% respectively.  ‚Åá br> The figures changed in undergraduate diplomas, in this section, women prevailed at 70% in comparison with rest categories. The figures females who have a Bachelor's degree was about 55%. Skilled vocational diploma has a lowest popular in women, it made up only 10%. The percentage females with postgraduate diploma and Master's degree was 30 and 40 respectively. Women figures instead were significant lower almost the half comparably to the men at 30% and 40%.  ‚Åá br>\n",
            "I0730 21:47:47.590172 140202429888384 utils.py:1122] decoded 1: correction: The bar chart illustrates information about the percentage between men and women at levels of post-school skills in Australia in the duration of 1999.  ‚Åá br> It is noticable that the figures in males who skilled vocational diploma was the highest and made up about 90%. The lowest persantage in men was the undergraduate diploma and came to approximately 35%. In terms of Bachelor's degree, postgraduate diploma and Master's degree in males the figures fell on 47%, 70% and 60% respectively.  ‚Åá br> The figures changed in undergraduate diplomas, in this section, women prevailed at 70% in comparison with rest categories. The figures females who have a Bachelor's degree was about 55%. Skilled vocational diploma has a lowest popular in women, it made up only 10%. The percentage females with postgraduate diploma and Master's degree was 30 and 40 respectively. Women figures instead were significant lower almost the half comparably to the men at 30% and 40%.  ‚Åá br>\n",
            "INFO:tensorflow:            -> The bar chart illustrates information about the percentage between men and women at levels of post-school skills in Australia in the duration of 1999.  ‚Åá br> It is noticable that the figures for males who received a skilled vocational diploma were the highest and made up about 90%. The lowest persantage for men was the undergraduate diploma and came to approximately 35%. In terms of Bachelor's degree, postgraduate diploma and Master's degree for males the figures fell to 47%, 70% and 60% respectively.  ‚Åá br> The figures changed in undergraduate diplomas. In this section, women prevailed at 70% in comparison with the rest categories. The figures for females who have a Bachelor's degree were about 55%. Skilled vocational diploma has the lowest popularity among women, it made up only 10%. The percentage of females with postgraduate diploma and Master's degree was 30 and 40 respectively. Women figures instead were significantly lower, almost half, compared to the men at 30% and 40%.  ‚Åá br>\n",
            "I0730 21:47:47.590339 140202429888384 utils.py:1123]             -> The bar chart illustrates information about the percentage between men and women at levels of post-school skills in Australia in the duration of 1999.  ‚Åá br> It is noticable that the figures for males who received a skilled vocational diploma were the highest and made up about 90%. The lowest persantage for men was the undergraduate diploma and came to approximately 35%. In terms of Bachelor's degree, postgraduate diploma and Master's degree for males the figures fell to 47%, 70% and 60% respectively.  ‚Åá br> The figures changed in undergraduate diplomas. In this section, women prevailed at 70% in comparison with the rest categories. The figures for females who have a Bachelor's degree were about 55%. Skilled vocational diploma has the lowest popularity among women, it made up only 10%. The percentage of females with postgraduate diploma and Master's degree was 30 and 40 respectively. Women figures instead were significantly lower, almost half, compared to the men at 30% and 40%.  ‚Åá br>\n",
            "INFO:tensorflow:decoded 2: correction: Some people think that social media in the Internet following purpose like give some information to people, but other people think that Facebook, Vkontakte and other media in the Internet just help people entertain.  ‚Åá br> People with the first idea may be true because Facebook and Vkontakte have many groups which showing differents news and have many comments about it. They presenting much advertising about new-opens cafe and lectures which soon are going happening in ypur city. Also, we can get known about lastly new booksor films, sometimes we can research texts of some objects and read it ourselves. On these sites we can see all information about people whose we know or just famous people. Many funats use these resurse that know what like and what doing their lovely stars in simple life. They can chatting with people who is unvalable but wont that other people get known what they feel or think about something.  ‚Åá br> However, many people don't use social media for take or get some information. They use Vkontakte that share their photos with other people, or use Facebook that look for their classmates or other friend who on the present days live other countries, because nowadays when is time of globalisation many people travell or work in other country.  ‚Åá br> In my opinion I agree with first and second ideas. Because we can use posibilities which we have. In the worls everytime somethings happend and modern men must know about all things. It's good idea share advertising on these sites that a lot of people get know what you want.  ‚Åá br>\n",
            "I0730 21:47:47.591994 140202429888384 utils.py:1122] decoded 2: correction: Some people think that social media in the Internet following purpose like give some information to people, but other people think that Facebook, Vkontakte and other media in the Internet just help people entertain.  ‚Åá br> People with the first idea may be true because Facebook and Vkontakte have many groups which showing differents news and have many comments about it. They presenting much advertising about new-opens cafe and lectures which soon are going happening in ypur city. Also, we can get known about lastly new booksor films, sometimes we can research texts of some objects and read it ourselves. On these sites we can see all information about people whose we know or just famous people. Many funats use these resurse that know what like and what doing their lovely stars in simple life. They can chatting with people who is unvalable but wont that other people get known what they feel or think about something.  ‚Åá br> However, many people don't use social media for take or get some information. They use Vkontakte that share their photos with other people, or use Facebook that look for their classmates or other friend who on the present days live other countries, because nowadays when is time of globalisation many people travell or work in other country.  ‚Åá br> In my opinion I agree with first and second ideas. Because we can use posibilities which we have. In the worls everytime somethings happend and modern men must know about all things. It's good idea share advertising on these sites that a lot of people get know what you want.  ‚Åá br>\n",
            "INFO:tensorflow:            -> Some people think that social media on the Internet serves a purpose like giving some information to people, but other people think that Facebook, Vkontakte and other media on the Internet just help people entertain.  ‚Åá br> People with the first idea may be true because Facebook and Vkontakte have many groups which show different news and have many comments about it. They present a lot of advertising about new cafes and lectures which are soon going to be held in your city. Also, we can get to know about recently new books or films. Sometimes we can research texts of some objects and read them ourselves. On these sites we can see all the information about people who we know or just famous people. Many people use these resources that know what they like and what they do with their lovely stars in simple life. They can chat with people who are unknown but wont let other people know what they feel or think about something.  ‚Åá br> However, many people don't use social media to get or get some information. They use Vkontakte to share their photos with other people, or use Facebook to look for their classmates or other friends who, nowadays, live in other countries, because nowadays, when it is the time of globalisation, many people travel or work in other countries.  ‚Åá br> In my opinion, I agree with the first and second ideas, because we can use the possibilities which we have. In the world, something happens and modern men must know about all things. It's a good idea to share advertising on these sites so that a lot of people get to know what you want.  ‚Åá br>\n",
            "I0730 21:47:47.592148 140202429888384 utils.py:1123]             -> Some people think that social media on the Internet serves a purpose like giving some information to people, but other people think that Facebook, Vkontakte and other media on the Internet just help people entertain.  ‚Åá br> People with the first idea may be true because Facebook and Vkontakte have many groups which show different news and have many comments about it. They present a lot of advertising about new cafes and lectures which are soon going to be held in your city. Also, we can get to know about recently new books or films. Sometimes we can research texts of some objects and read them ourselves. On these sites we can see all the information about people who we know or just famous people. Many people use these resources that know what they like and what they do with their lovely stars in simple life. They can chat with people who are unknown but wont let other people know what they feel or think about something.  ‚Åá br> However, many people don't use social media to get or get some information. They use Vkontakte to share their photos with other people, or use Facebook to look for their classmates or other friends who, nowadays, live in other countries, because nowadays, when it is the time of globalisation, many people travel or work in other countries.  ‚Åá br> In my opinion, I agree with the first and second ideas, because we can use the possibilities which we have. In the world, something happens and modern men must know about all things. It's a good idea to share advertising on these sites so that a lot of people get to know what you want.  ‚Åá br>\n",
            "INFO:tensorflow:decoded 4: correction: In modern world our life is demanding more and more different knowledge and skills from us so to set it children from early age go to some lessons and courses. Because of it they usually spend quite a little time outside and do not aware of all value and beauty of our nature, I can partly asree with this statement.  ‚Åá br> From one side, it is true that nowdays children spent less time outside enjoying some simple things such as trees, grass, sun and fresh air. Even when they go for a walk, in big sities it is complicated to find place where virgin nature is saved. They have to walk around blocks of flats and roads where no fresh air or spectacular views are left, although they are very important.  ‚Åá br> From other side, there is a lot of time children have to spend learning nature. They all have holidays when parents try to send they to different camps in forests or round the sea, to countryside where a lot of them have relatives or friends and so on.  ‚Åá br> So in this time children have enough space and hours to learn more about nature, to learn to understand and appreciate it, to see how many it can give us and enjoy all of its advantages.  ‚Åá br> To sum up, it is harder for children to spend a lot of time outside learning the nature now than it was before because of crazy life rhythm but there are quite a lot of possibilities to do it if they want.  ‚Åá br>\n",
            "I0730 21:47:47.672796 140202429888384 utils.py:1122] decoded 4: correction: In modern world our life is demanding more and more different knowledge and skills from us so to set it children from early age go to some lessons and courses. Because of it they usually spend quite a little time outside and do not aware of all value and beauty of our nature, I can partly asree with this statement.  ‚Åá br> From one side, it is true that nowdays children spent less time outside enjoying some simple things such as trees, grass, sun and fresh air. Even when they go for a walk, in big sities it is complicated to find place where virgin nature is saved. They have to walk around blocks of flats and roads where no fresh air or spectacular views are left, although they are very important.  ‚Åá br> From other side, there is a lot of time children have to spend learning nature. They all have holidays when parents try to send they to different camps in forests or round the sea, to countryside where a lot of them have relatives or friends and so on.  ‚Åá br> So in this time children have enough space and hours to learn more about nature, to learn to understand and appreciate it, to see how many it can give us and enjoy all of its advantages.  ‚Åá br> To sum up, it is harder for children to spend a lot of time outside learning the nature now than it was before because of crazy life rhythm but there are quite a lot of possibilities to do it if they want.  ‚Åá br>\n",
            "INFO:tensorflow:            -> In the modern world our life is demanding more and more different knowledge and skills from us so to set it, children from an early age go to some lessons and courses. Because of this, they usually spend quite a little time outside and are not aware of all the value and beauty of our nature. I can partly agree with this statement.  ‚Åá br> On the one hand, it is true that nowadays children spend less time outside enjoying some simple things such as trees, grass, the sun and fresh air. Even when they go for a walk, in big cities it is complicated to find a place where virgin nature is saved. They have to walk around blocks of flats and roads where no fresh air or spectacular views are left, although they are very important.  ‚Åá br> On the other hand, there is a lot of time children have to spend learning about nature. They all have holidays when parents try to send them to different camps in forests or around the sea, to countryside where a lot of them have relatives or friends and so on.  ‚Åá br> So, at this time, children have enough space and hours to learn more about nature, to learn to understand and appreciate it, to see how much it can give us and enjoy all of its advantages.  ‚Åá br> To sum up, it is harder for children to spend a lot of time outside learning about nature now than it was before because of the crazy life rhythm but there are quite a lot of possibilities to do it if they want.  ‚Åá br>\n",
            "I0730 21:47:47.673023 140202429888384 utils.py:1123]             -> In the modern world our life is demanding more and more different knowledge and skills from us so to set it, children from an early age go to some lessons and courses. Because of this, they usually spend quite a little time outside and are not aware of all the value and beauty of our nature. I can partly agree with this statement.  ‚Åá br> On the one hand, it is true that nowadays children spend less time outside enjoying some simple things such as trees, grass, the sun and fresh air. Even when they go for a walk, in big cities it is complicated to find a place where virgin nature is saved. They have to walk around blocks of flats and roads where no fresh air or spectacular views are left, although they are very important.  ‚Åá br> On the other hand, there is a lot of time children have to spend learning about nature. They all have holidays when parents try to send them to different camps in forests or around the sea, to countryside where a lot of them have relatives or friends and so on.  ‚Åá br> So, at this time, children have enough space and hours to learn more about nature, to learn to understand and appreciate it, to see how much it can give us and enjoy all of its advantages.  ‚Åá br> To sum up, it is harder for children to spend a lot of time outside learning about nature now than it was before because of the crazy life rhythm but there are quite a lot of possibilities to do it if they want.  ‚Åá br>\n",
            "INFO:tensorflow:decoded 8: correction: In modern world our life is demanding more and more different knowledge and skills from us so to set it children from early age go to some lessons and courses. Because of it they usually spend quite a little time outside and do not aware of all value and beauty of our nature, I can partly asree with this statement.  ‚Åá br> From one side, it is true that nowdays children spent less time outside enjoying some simple things such as trees, grass, sun and fresh air. Even when they go for a walk, in big sities it is complicated to find place where virgin nature is saved. They have to walk around blocks of flats and roads where no fresh air or spectacular views are left, although they are very important.  ‚Åá br> From other side, there is a lot of time children have to spend learning nature. They all have holidays when parents try to send they to different camps in forests or round the sea, to countryside where a lot of them have relatives or friends and so on.  ‚Åá br> So in this time children have enough space and hours to learn more about nature, to learn to understand and appreciate it, to see how many it can give us and enjoy all of its advantages.  ‚Åá br> To sum up, it is harder for children to spend a lot of time outside learning the nature now than it was before because of crazy life rhythm but there are quite a lot of possibilities to do it if they want.  ‚Åá br>\n",
            "I0730 21:47:47.678169 140202429888384 utils.py:1122] decoded 8: correction: In modern world our life is demanding more and more different knowledge and skills from us so to set it children from early age go to some lessons and courses. Because of it they usually spend quite a little time outside and do not aware of all value and beauty of our nature, I can partly asree with this statement.  ‚Åá br> From one side, it is true that nowdays children spent less time outside enjoying some simple things such as trees, grass, sun and fresh air. Even when they go for a walk, in big sities it is complicated to find place where virgin nature is saved. They have to walk around blocks of flats and roads where no fresh air or spectacular views are left, although they are very important.  ‚Åá br> From other side, there is a lot of time children have to spend learning nature. They all have holidays when parents try to send they to different camps in forests or round the sea, to countryside where a lot of them have relatives or friends and so on.  ‚Åá br> So in this time children have enough space and hours to learn more about nature, to learn to understand and appreciate it, to see how many it can give us and enjoy all of its advantages.  ‚Åá br> To sum up, it is harder for children to spend a lot of time outside learning the nature now than it was before because of crazy life rhythm but there are quite a lot of possibilities to do it if they want.  ‚Åá br>\n",
            "INFO:tensorflow:            -> In the modern world our life is demanding more and more different knowledge and skills from us so to set it, children from an early age go to some lessons and courses. Because of this, they usually spend quite a little time outside and are not aware of all the value and beauty of our nature. I can partly agree with this statement.  ‚Åá br> On the one hand, it is true that nowadays children spend less time outside enjoying some simple things such as trees, grass, the sun and fresh air. Even when they go for a walk, in big cities it is complicated to find a place where virgin nature is saved. They have to walk around blocks of flats and roads where no fresh air or spectacular views are left, although they are very important.  ‚Åá br> On the other hand, there is a lot of time children have to spend learning about nature. They all have holidays when parents try to send them to different camps in forests or around the sea, to countryside where a lot of them have relatives or friends and so on.  ‚Åá br> So, at this time, children have enough space and hours to learn more about nature, to learn to understand and appreciate it, to see how much it can give us and enjoy all of its advantages.  ‚Åá br> To sum up, it is harder for children to spend a lot of time outside learning about nature now than it was before because of the crazy life rhythm but there are quite a lot of possibilities to do it if they want.  ‚Åá br>\n",
            "I0730 21:47:47.678362 140202429888384 utils.py:1123]             -> In the modern world our life is demanding more and more different knowledge and skills from us so to set it, children from an early age go to some lessons and courses. Because of this, they usually spend quite a little time outside and are not aware of all the value and beauty of our nature. I can partly agree with this statement.  ‚Åá br> On the one hand, it is true that nowadays children spend less time outside enjoying some simple things such as trees, grass, the sun and fresh air. Even when they go for a walk, in big cities it is complicated to find a place where virgin nature is saved. They have to walk around blocks of flats and roads where no fresh air or spectacular views are left, although they are very important.  ‚Åá br> On the other hand, there is a lot of time children have to spend learning about nature. They all have holidays when parents try to send them to different camps in forests or around the sea, to countryside where a lot of them have relatives or friends and so on.  ‚Åá br> So, at this time, children have enough space and hours to learn more about nature, to learn to understand and appreciate it, to see how much it can give us and enjoy all of its advantages.  ‚Åá br> To sum up, it is harder for children to spend a lot of time outside learning about nature now than it was before because of the crazy life rhythm but there are quite a lot of possibilities to do it if they want.  ‚Åá br>\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "I0730 21:47:47.689082 140202429888384 tpu_estimator.py:617] Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "I0730 21:47:47.689297 140202429888384 tpu_estimator.py:621] Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "I0730 21:47:49.209216 140202429888384 tpu_estimator.py:625] Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "I0730 21:47:49.209533 140202429888384 tpu_estimator.py:442] Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "I0730 21:47:49.209755 140199045883648 tpu_estimator.py:437] InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "I0730 21:47:49.209860 140199045883648 tpu_estimator.py:548] Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "I0730 21:47:49.210007 140202429888384 error_handling.py:115] infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "I0730 21:47:49.210139 140202429888384 tpu_estimator.py:629] Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "I0730 21:47:49.210246 140202429888384 tpu_estimator.py:442] Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "I0730 21:47:49.210427 140199037490944 tpu_estimator.py:437] OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "I0730 21:47:49.210508 140199037490944 tpu_estimator.py:563] Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "I0730 21:47:49.210656 140202429888384 error_handling.py:115] outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "I0730 21:47:49.210794 140202429888384 tpu_estimator.py:633] Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "I0730 21:47:49.456799 140202429888384 error_handling.py:115] prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "I0730 21:47:49.457364 140202429888384 error_handling.py:115] prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zv4BhgkQak-5"
      },
      "source": [
        "And then, finally, we glue our processed texts back together to produce the outputs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VymUL8RwadVd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d5fbace-420b-4436-a2d1-7f68f9020b75"
      },
      "source": [
        "%%bash\n",
        "source activate heptabot\n",
        "python process_output.py"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing TPU model outputs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]\r 33%|‚ñà‚ñà‚ñà‚ñé      | 1/3 [00:01<00:03,  1.54s/it]\r 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 2/3 [00:02<00:01,  1.09s/it]\r100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  1.48s/it]\r100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:04<00:00,  1.42s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cK8wUBgWsoD"
      },
      "source": [
        "## Display the results\n",
        "\n",
        "In this section we show the processed results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOCnVcL2afCl",
        "cellView": "form"
      },
      "source": [
        "#@markdown This cell hides a function to make pretty displaying work\n",
        "def prepare_display(filekey):\n",
        "  template = \"\"\"<html><head>\n",
        "\t<meta charset=\"utf-8\">\n",
        "\t<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\">\n",
        "\t<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n",
        "\t<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\">\n",
        "\t<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\">\n",
        "\t<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js\"></script>\n",
        "\t<link href=\"https://getbootstrap.com/docs/3.3/dist/css/bootstrap.min.css\" rel=\"stylesheet\"><!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->\n",
        "\t<link href=\"https://getbootstrap.com/docs/3.3/assets/css/ie10-viewport-bug-workaround.css\" rel=\"stylesheet\"><!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->\n",
        "\t<link href=\"https://fonts.googleapis.com/css2?family=Kanit&family=Mukta&family=PT+Sans&family=PT+Serif&family=Ubuntu+Mono&display=swap\" rel=\"stylesheet\">\n",
        "<style>\n",
        "{0}\n",
        "</style>\n",
        "<script type=\"text/javascript\">\n",
        "{1}\n",
        "</script>\n",
        "</head>\n",
        "<body>\n",
        "<div class=\"header2\">{2}</div><br>\n",
        "{3}\n",
        "</body></html>\"\"\"\n",
        "\n",
        "  with open(\"static/result/style.css\", \"r\") as inhtml:\n",
        "    style = inhtml.read()\n",
        "  with open(\"static/result/engine.js\", \"r\") as inhtml:\n",
        "    script = inhtml.read().replace(\"var em;\", \"var em=18;\").replace(\"elemtitle.style.top = (rect.top - prect.top) + 'px';\", \"elemtitle.style.top = (rect.top - prect.top) + 6 + 'px';\")\n",
        "  with open(os.path.join('./output', filekey + \".html\"), \"r\") as inhtml:\n",
        "    htmlcont = inhtml.read()\n",
        "  tt = re.search(r'<div class=\"header2\">(.*?)</div>', htmlcont, flags=re.DOTALL).group(1)\n",
        "  result_div = re.search(r'<div id=\"resulta\".*?\\n', htmlcont).group(0)\n",
        "  outcont = template.format(style, script, tt, result_div)\n",
        "  with open(\"display.html\", \"w\", encoding=\"utf-8\") as outhtml:\n",
        "    outhtml.write(outcont)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "N7iwGpiIZ0cS",
        "outputId": "5a0ea323-bb42-4e0f-d388-ddb0279483e2"
      },
      "source": [
        "#@markdown Enter the desired text ID below to pretty-print the result\n",
        "display_id = chosen_one  #@param {type: \"string\"}\n",
        "\n",
        "prepare_display(display_id)\n",
        "IPython.display.HTML(filename='display.html')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<html><head>\n",
              "\t<meta charset=\"utf-8\">\n",
              "\t<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\">\n",
              "\t<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n",
              "\t<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\">\n",
              "\t<meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\">\n",
              "\t<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js\"></script>\n",
              "\t<link href=\"https://getbootstrap.com/docs/3.3/dist/css/bootstrap.min.css\" rel=\"stylesheet\"><!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->\n",
              "\t<link href=\"https://getbootstrap.com/docs/3.3/assets/css/ie10-viewport-bug-workaround.css\" rel=\"stylesheet\"><!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->\n",
              "\t<link href=\"https://fonts.googleapis.com/css2?family=Kanit&family=Mukta&family=PT+Sans&family=PT+Serif&family=Ubuntu+Mono&display=swap\" rel=\"stylesheet\">\n",
              "<style>\n",
              "html {\n",
              "\toverflow-x: hidden;\n",
              "\tanimation: fadein 1s;\n",
              "\t-moz-animation: fadein 1s;\n",
              "\t/* Firefox */\n",
              "\t-webkit-animation: fadein 1s;\n",
              "\t/* Safari and Chrome */\n",
              "\t-o-animation: fadein 1s;\n",
              "\t/* Opera */\n",
              "\tfont-size: 18px;\n",
              "}\n",
              ".loadout {\n",
              "\tanimation: fadeout 1s;\n",
              "\t-moz-animation: fadeout 1s;\n",
              "\t-webkit-animation: fadeout 1s;\n",
              "\t-o-animation: fadeout 1s;\n",
              "}\n",
              "/* font-size calc lock */\n",
              ".logo {\n",
              "\tfont-size: 2.5rem;\n",
              "\tgrid-template-columns: 2.75rem calc( 2.5rem * 4 );\n",
              "\tgrid-gap: 0px .5rem;\n",
              "\tbackground: white;\n",
              "}\n",
              "#logo-text {\n",
              "\tline-height: 2rem;\n",
              "\talign-self: center;\n",
              "}\n",
              ".header2 {\n",
              "\tfont-size: 1.0625rem;\n",
              "}\n",
              "#inputa, #resulta {\n",
              "\tfont-size: .825rem;\n",
              "}\n",
              "#motto {\n",
              "\tfont-size: 1.125rem;\n",
              "}\n",
              ".footer {\n",
              "\tfont-size: .75rem;\n",
              "}\n",
              ".regular-text {\n",
              "\tfont-size: .825rem;\n",
              "}\n",
              "@media screen and (min-width: 20em) {\n",
              "\t.logo {\n",
              "\t\tfont-size: calc( 2.5rem + .9375 * (100vw - 20rem) / (60 - 20) );\n",
              "\t\tgrid-template-columns: 2.75rem calc( (2.5rem + .9375 * (100vw - 20rem) / (60 - 20)) * 4 );\n",
              "\t\tgrid-gap: 0px .5rem;\n",
              "\t}\n",
              "\t#logo-text {\n",
              "\t\tline-height: calc( 2rem + 1.75 * (100vw - 20rem) / (60 - 20) );\n",
              "\t\talign-self: center;\n",
              "\t}\n",
              "\t.footer {\n",
              "\t\tfont-size: calc( .75rem + .25 * (100vw - 20rem) / (60 - 20) );\n",
              "\t}\n",
              "\t#motto {\n",
              "\t\tfont-size: calc( 1.125rem + .125 * (100vw - 20rem) / (60 - 20) );\n",
              "\t}\n",
              "\t.header2 {\n",
              "\t\tfont-size: calc( 1.0625rem + .125 * (100vw - 20rem) / (60 - 20) );\n",
              "\t}\n",
              "\t#inputa, #resulta {\n",
              "\t\tfont-size: calc( .825rem + .125 * (100vw - 20rem) / (60 - 20) );\n",
              "\t}\n",
              "\t.regular-text {\n",
              "\t\tfont-size: calc( .825rem + .125 * (100vw - 20rem) / (60 - 20) );\n",
              "\t}\n",
              "}\n",
              "@media (min-width: 60em) {\n",
              "\t.logo {\n",
              "\t\tfont-size: calc( 2.5rem + .9375rem );\n",
              "\t\tgrid-template-columns: 2.75rem calc( (2.5rem + .9375rem) * 4 );\n",
              "\t\tgrid-gap: 0px .75rem;\n",
              "\t}\n",
              "\t#logo-text {\n",
              "\t\tline-height: calc( 2rem + 1.75rem );\n",
              "\t\talign-self: end;\n",
              "\t}\n",
              "\n",
              "\t.footer {\n",
              "\t\tfont-size: calc( .75rem + .25rem );\n",
              "\t}\n",
              "\t#motto {\n",
              "\t\tfont-size: calc( 1.125rem + .125rem );\n",
              "\t}\n",
              "\t#inputa, #resulta {\n",
              "\t\tfont-size: calc( .825rem + .125rem );\n",
              "\t}\n",
              "\t.header2 {\n",
              "\t\tfont-size: calc( 1.0625rem + .125rem );\n",
              "\t}\n",
              "\t.regular-text {\n",
              "\t\tfont-size: calc( .825rem + .125rem );\n",
              "\t}\n",
              "}\n",
              "body {\n",
              "\tfont-family: PT Sans, sans-serif;\n",
              "\toverflow: hidden;\n",
              "\tcolor: #3c4752;\n",
              "}\n",
              "body * {\n",
              "\tcursor: default;\n",
              "}\n",
              "main, footer {\n",
              "\tbackground: white;\n",
              "\tz-index: 1;\n",
              "}\n",
              ".animate-out {\n",
              "\t-webkit-transition: opacity 1s;\n",
              "\ttransition: opacity 1s;\n",
              "\topacity: 0;\n",
              "}\n",
              ".u {\n",
              "\tlist-style: none;\n",
              "\tpadding: 0;\n",
              "\tmargin: 0;\n",
              "}\n",
              ".l {\n",
              "\tpadding-left: 1em;\n",
              "\ttext-indent: -.7em;\n",
              "\tmargin: calc( (3.3vh - 12 * ((100vh - 500px) / 800)) / 2) 0;\n",
              "}\n",
              ".l:before {\n",
              "\tcontent: \"‚Ä¢ \";\n",
              "\tcolor: #5b6c7d;\n",
              "}\n",
              ".header2 {\n",
              "\tfont-family: PT Sans;\n",
              "\tdisplay: inline-block;\n",
              "}\n",
              ".duo {\n",
              "background: #FDD1BE;\n",
              "display: inline-block;\n",
              "}\n",
              ".stop {\n",
              "   max-width: 100vw;\n",
              "}\n",
              ".stoprow {\n",
              "   max-width: 100vw;\n",
              "   width: 100%;\n",
              "   margin-left: 0px !important;\n",
              "   margin-right: 0px !important;\n",
              "}\n",
              "@font-face {\n",
              "\tfont-family: 'Open Sans', sans-serif;\n",
              "}\n",
              "@keyframes fadein {\n",
              "\tfrom {\n",
              "\t\topacity: 0;\n",
              "\t}\n",
              "\tto {\n",
              "\t\topacity: 1;\n",
              "\t}\n",
              "}\n",
              "@-moz-keyframes fadein {\n",
              "\t/* Firefox */\n",
              "\tfrom {\n",
              "\t\topacity: 0;\n",
              "\t}\n",
              "\tto {\n",
              "\t\topacity: 1;\n",
              "\t}\n",
              "}\n",
              "@-webkit-keyframes fadein {\n",
              "\t/* Safari and Chrome */\n",
              "\tfrom {\n",
              "\t\topacity: 0;\n",
              "\t}\n",
              "\tto {\n",
              "\t\topacity: 1;\n",
              "\t}\n",
              "}\n",
              "@-o-keyframes fadein {\n",
              "\t/* Opera */\n",
              "\tfrom {\n",
              "\t\topacity: 0;\n",
              "\t}\n",
              "\tto {\n",
              "\t\topacity: 1;\n",
              "\t}\n",
              "}\n",
              "@keyframes fadeout {\n",
              "\tfrom {\n",
              "\t\topacity: 1;\n",
              "\t}\n",
              "\tto {\n",
              "\t\topacity: 0;\n",
              "\t}\n",
              "}\n",
              "@-moz-keyframes fadeout {\n",
              "\t/* Firefox */\n",
              "\tfrom {\n",
              "\t\topacity: 1;\n",
              "\t}\n",
              "\tto {\n",
              "\t\topacity: 0;\n",
              "\t}\n",
              "}\n",
              "@-webkit-keyframes fadeout {\n",
              "\t/* Safari and Chrome */\n",
              "\tfrom {\n",
              "\t\topacity: 1;\n",
              "\t}\n",
              "\tto {\n",
              "\t\topacity: 0;\n",
              "\t}\n",
              "}\n",
              "@-o-keyframes fadeout {\n",
              "\t/* Opera */\n",
              "\tfrom {\n",
              "\t\topacity: 1;\n",
              "\t}\n",
              "\tto {\n",
              "\t\topacity: 0;\n",
              "\t}\n",
              "}\n",
              "input {\n",
              "\tcursor: pointer !important;\n",
              "}\n",
              "a:link {\n",
              "\tz-index: 1;\n",
              "\ttext-decoration: none;\n",
              "\tcursor: pointer !important;\n",
              "\tcolor: #61186d;\n",
              "\topacity: 1;\n",
              "\ttransition: opacity .15s ease-in-out;\n",
              "\t-moz-transition: opacity .15s ease-in-out;\n",
              "\t-webkit-transition: opacity .15s ease-in-out;\n",
              "\t-ms-transition: opacity .15s ease-in-out;\n",
              "\t-o-transition: opacity .15s ease-in-out;\n",
              "}\n",
              "a:hover {\n",
              "\tz-index: 1;\n",
              "\topacity: 0.7;\n",
              "\ttext-decoration: none !important;\n",
              "}\n",
              "a:visited {\n",
              "\tz-index: 1;\n",
              "\tcolor: #61186d;\n",
              "}\n",
              ".navbar {\n",
              "  /* min-height: 80px; */\n",
              "}\n",
              ".navbar-brand {\n",
              "  padding: 0 15px;\n",
              "  height: 80px;\n",
              "  line-height: 80px;\n",
              "}\n",
              ".navbar-toggle {\n",
              "  /* (80px - button height 34px) / 2 = 23px */\n",
              "  margin-top: 18px;\n",
              "  padding: 9px 10px !important;\n",
              "  margin-bottom: 18px;\n",
              "}\n",
              "@media (min-width: 768px) {\n",
              "  .navbar-nav > li > a {\n",
              "    /* (80px - line-height of 27px) / 2 = 26.5px */\n",
              "    padding-top: 26.5px;\n",
              "    padding-bottom: 26.5px;\n",
              "    line-height: 27px;\n",
              "  }\n",
              "}\n",
              ".nav {\n",
              "\tz-index: 1;\n",
              "}\n",
              "#navbar {\n",
              "\tz-index: 3;\n",
              "}\n",
              ".flag {\n",
              "\tz-index: 1;\n",
              "\theight: calc( 3vh - 12 * ((100vh - 500px) / 1500));\n",
              "\tpadding-bottom: 0.7vh;\n",
              "}\n",
              ".darken {\n",
              "\tdisplay: inline;\n",
              "\tcolor: #000000;\n",
              "}\n",
              ".c {\n",
              "\tdisplay: inline-block;\n",
              "}\n",
              ".nav-link {\n",
              "\tz-index: 1;\n",
              "\tdisplay: block;\n",
              "\tpadding-top: 3.2vh;\n",
              "\tpadding-right: 0.3rem;\n",
              "\tpadding-bottom: 0rem;\n",
              "\tpadding-left: 0.6rem;\n",
              "}\n",
              "footer {\n",
              "\tz-index: 1;\n",
              "\tbackground: white;\n",
              "\twidth: 100%;\n",
              "\tbottom: 0px;\n",
              "\tposition: fixed;\n",
              "}\n",
              ".active * {\n",
              "\tbackground-color: rgba(0, 0, 0, 0.07) !important;\n",
              "}\n",
              ".navbar-toggle {\n",
              "\tbackground-color: rgba(0, 0, 0, 0.07) !important;\n",
              "\tborder-color: rgba(0, 0, 0, 0.1) !important;\n",
              "}\n",
              ".collapsed {\n",
              "\tbackground-color: rgba(0, 0, 0, 0) !important;\n",
              "}\n",
              "#upper-ribbon {\n",
              "\tposition: fixed;\n",
              "\tmargin-top: -0.5vh;\n",
              "\tz-index: 3; \n",
              "}\n",
              ".box-shadow {\n",
              "\tbox-shadow: 0 .25rem .75rem rgba(0, 0, 0, .05);\n",
              "}\n",
              ".shade-gray {\n",
              "\tz-index: 1;\n",
              "\tbackground: linear-gradient(rgba(200, 200, 200, 0), white);\n",
              "}\n",
              ".stripes {\n",
              "\tz-index: 1;\n",
              "\tbackground: #b36a40; /* Old browsers */\n",
              "\tbackground: -moz-linear-gradient(-45deg, #b36a40 0%, #b36a40 69%, #5b6c7d 79%); /* FF3.6-15 */\n",
              "\tbackground: -webkit-linear-gradient(-45deg, #b36a40 0%, #b36a40 69%,#5b6c7d 79%); /* Chrome10-25,Safari5.1-6 */\n",
              "\tbackground: linear-gradient(135deg, #b36a40 0%,#b36a40 69%, #5b6c7d 79%); /* W3C, IE10+, FF16+, Chrome26+, Opera12+, Safari7+ */\n",
              "\tfilter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#b36a40', endColorstr='#5b6c7d',GradientType=1 ); /* IE6-9 fallback on horizontal gradient */\n",
              "\theight: 0.75vh;\n",
              "}\n",
              ".pale {\n",
              "\tz-index: 1;\n",
              "\tbackground: #5b6c7d; /* Old browsers */\n",
              "\tbackground: -moz-linear-gradient(-45deg, #5b6c7d 0%, #5b6c7d 69%, #b36a40 79%); /* FF3.6-15 */\n",
              "\tbackground: -webkit-linear-gradient(-45deg, #5b6c7d 0%,#5b6c7d 69%,#b36a40 79%); /* Chrome10-25,Safari5.1-6 */\n",
              "\tbackground: linear-gradient(135deg, #5b6c7d 0%,#5b6c7d 69%,#b36a40 79%); /* W3C, IE10+, FF16+, Chrome26+, Opera12+, Safari7+ */\n",
              "\tfilter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#5b6c7d', endColorstr='#b36a40',GradientType=1 ); /* IE6-9 fallback on horizontal gradient */\n",
              "\theight: 0.75vh;\n",
              "}\n",
              ".lead-space {\n",
              "\tz-index: 1;\n",
              "\theight: calc( 4vh - 2 * ((100vh - 700px) / 100));\n",
              "\twidth: 100vw;\n",
              "}\n",
              ".lead {\n",
              "\tz-index: 1;\n",
              "\tfont-size: calc( 4vh - 2 * ((100vh - 700px) / 100));\n",
              "\tpadding: 0px 5px 0px 5px;\n",
              "}\n",
              ".upper-lead {\n",
              "\tz-index: 1;\n",
              "\tbackground: rgba(200, 200, 200, 0);\n",
              "\twidth: 100vw;\n",
              "\toverflow: hidden !important;\n",
              "\ttext-align: center;\n",
              "}\n",
              ".maintext {\n",
              "\tz-index: 1;\n",
              "\tfont-size: calc( 3.3vh - 12 * ((100vh - 500px) / 800));\n",
              "\tpadding: 0px 7px 0px 7px;\n",
              "}\n",
              ".logo {\n",
              "\tposition: absolute;\n",
              "\tmargin: 3px 0px 3px 0px;\n",
              "\tbackground: white;\n",
              "\ttop: 0px;\n",
              "\tleft: 0px;\n",
              "\twidth: 100vw;\n",
              "\tcolor: black;\n",
              "\tfont-family: Kanit;\n",
              "\tjustify-content: center;\n",
              "\tdisplay: grid;\n",
              "\tgrid-template-areas:\n",
              "\t\t\"logo logotext\"\n",
              "\t\t\"motto motto\";\n",
              "\talign-items: center;\n",
              "\ttext-decoration: none;\n",
              "}\n",
              ".logo:before {\n",
              "    content: '';\n",
              "    position: absolute;\n",
              "    top: -3px;\n",
              "    background: white;\n",
              "    height: 3px;\n",
              "\twidth: 100%;\n",
              "}\n",
              "#logo-text {\n",
              "\tdisplay: inline;\n",
              "\ttext-align: center;\n",
              "\tgrid-area: logotext;\n",
              "}\n",
              "#logo-svg {\n",
              "\twidth: 2.75rem;\n",
              "\tgrid-area: logo;\n",
              "\tjustify-self: end;\n",
              "}\n",
              "#motto {\n",
              "\tfont-family: PT Sans;\n",
              "\ttext-align: center;\n",
              "\tgrid-area: motto;\n",
              "}\n",
              ".filler {\n",
              "\tz-index: 1;\n",
              "\twidth: 100vw;\n",
              "\tmargin: 0px 0px 0px 0px;\n",
              "}\n",
              ".fake * {\n",
              "\tz-index: -1;\n",
              "\tposition: relative;\n",
              "\tvisibility: hidden;\n",
              "}\n",
              ".fake {\n",
              "\tz-index: -1;\n",
              "\tposition: relative;\n",
              "\tvisibility: hidden;\n",
              "}\n",
              ".palelink {\n",
              "\tz-index: 1;\n",
              "\tcolor: #5b6c7d !important;\n",
              "}\n",
              ".f {\n",
              "\ttext-align: center;\n",
              "\tmax-width: 2096px;\n",
              "}\n",
              "#inputa {\n",
              "\tfont-family: PT Serif;\n",
              "\twidth: 100%;\n",
              "\tborder-width: 0.5px;\n",
              "\tborder-radius: 4px;\n",
              "\tresize: none;\n",
              "\toverflow: hidden;\n",
              "}\n",
              "#resulta {\n",
              "\tfont-family: PT Serif;\n",
              "\twidth: 100%;\n",
              "\tpadding-top: 2.5px;\n",
              "\tpadding-left: 2.5px;\n",
              "\tresize: none;\n",
              "\toverflow: hidden;\n",
              "}\n",
              ".error-type {\n",
              "    position: absolute;\n",
              "    border-radius: .4em;\n",
              "    border-style: solid;\n",
              "    border-width: 2px;\n",
              "    padding: 0px 2px 0px 2px;\n",
              "    font-family: PT Sans;\n",
              "\tcolor: black !important;\n",
              "    --left-pos: 0px;\n",
              "}\n",
              ".error-type:after {\n",
              "    content: '';\n",
              "    position: absolute;\n",
              "    bottom: 0;\n",
              "    left: var(--left-pos);\n",
              "    width: 0;\n",
              "    height: 0;\n",
              "    border: 0.375em solid transparent;\n",
              "    border-top-color: inherit;\n",
              "    border-bottom: 0;\n",
              "    margin-left: -0.375em;\n",
              "    margin-bottom: -0.375em;\n",
              "}\n",
              "ins {\n",
              "\ttext-decoration: none;\n",
              "\tbackground-color: transparent !important;\n",
              "\t-webkit-text-stroke-width: 0.045em;\n",
              "}\n",
              "del {\n",
              "  text-decoration: none;\n",
              "  background-color: transparent !important;\n",
              "  color: black !important;\n",
              "  background-image: linear-gradient(transparent 45%, var(--dash-color) 45%, var(--dash-color) 65%, transparent 65%);\n",
              "}\n",
              ".comp {\n",
              "    background-color: #b3adf0;\n",
              "\tborder-color: #7460b6;\n",
              "\ttext-decoration-color: #7460b6;\n",
              "\tcolor: #7460b6;\n",
              "\t--dash-color: #7460b6;\n",
              "}\n",
              ".punct {\n",
              "    background-color: #ffb0ca;\n",
              "\tborder-color: #d8386d;\n",
              "\ttext-decoration-color: #d8386d;\n",
              "\tcolor: #d8386d;\n",
              "\t--dash-color: #d8386d;\n",
              "}\n",
              ".disc {\n",
              "    background-color: #e6b6ac;\n",
              "\tborder-color: #8d5746;\n",
              "\ttext-decoration-color: #8d5746;\n",
              "\tcolor: #8d5746;\n",
              "\t--dash-color: #8d5746;\n",
              "}\n",
              ".spell {\n",
              "    background-color: #fefea3;\n",
              "\tborder-color: #fdbd28;\n",
              "\ttext-decoration-color: #fdbd28;\n",
              "\tcolor: #fdbd28;\n",
              "\t--dash-color: #fdbd28;\n",
              "}\n",
              ".vocab {\n",
              "    background-color: #b8e1b8;\n",
              "\tborder-color: #8cbf8c;\n",
              "\ttext-decoration-color: #8cbf8c;\n",
              "\tcolor: #8cbf8c;\n",
              "\t--dash-color: #8cbf8c;\n",
              "}\n",
              ".gram {\n",
              "    background-color: #ffc891;\n",
              "\tborder-color: #e36622;\n",
              "\ttext-decoration-color: #e36622;\n",
              "\tcolor: #e36622;\n",
              "\t--dash-color: #e36622;\n",
              "}\n",
              ".none {\n",
              "\tdisplay: none;\n",
              "}\n",
              ".error-hider {\n",
              "\tbackground-clip: content-box;\n",
              "    border-left-style: solid;\n",
              "    border-left-width: .2rem;\n",
              "    transform: translateY(2px);\n",
              "\tcursor: pointer;\n",
              "    color: rgb(0, 0, 0);\n",
              "    display: inline-block;\n",
              "    margin-left: 1px;\n",
              "    padding-right: 2px;\n",
              "    font-family: Roboto, RobotoDraft, Helvetica, Arial, sans-serif;\n",
              "    font-size: 0px;\n",
              "    font-weight: 400;\n",
              "    height: .825rem;\n",
              "    white-space: normal;\n",
              "    width: 0px;\n",
              "    -webkit-tap-highlight-color: rgba(0, 0, 0, 0);\n",
              "}\n",
              ".error-hider:before {\n",
              "    top: -.3rem;\n",
              "    content: '';\n",
              "    background-color: var(--dash-color);\n",
              "    color: rgb(0, 0, 0);\n",
              "    cursor: pointer;\n",
              "    display: block;\n",
              "    font-family: Roboto, RobotoDraft, Helvetica, Arial, sans-serif;\n",
              "    font-size: 0px;\n",
              "    font-weight: 400;\n",
              "    height: .4rem;\n",
              "    left: -.3rem;\n",
              "    opacity: 1;\n",
              "    position: absolute;\n",
              "    bottom: -0.4rem;\n",
              "    white-space: normal;\n",
              "    width: .4rem;\n",
              "    -webkit-tap-highlight-color: rgba(0, 0, 0, 0);\n",
              "}\n",
              "\n",
              "</style>\n",
              "<script type=\"text/javascript\">\n",
              "window.addEventListener(\"beforeunload\", function () {\n",
              "\tdocument.body.classList.add(\"animate-out\");\n",
              "});\n",
              "\n",
              "var tx = document.getElementsByTagName('textarea');\n",
              "for (var i = 0; i < tx.length; i++) {\n",
              "  tx[i].setAttribute('style', 'height:' + (tx[i].scrollHeight) + 'px;overflow-y:hidden;');\n",
              "  tx[i].addEventListener(\"input\", OnInput, false);\n",
              "}\n",
              "\n",
              "function OnInput() {\n",
              "  this.style.height = 'auto';\n",
              "  this.style.height = (this.scrollHeight) + 'px';\n",
              "}\n",
              "\n",
              "function fadein (object,mls) {\n",
              "\tif (object.style.opacity) {\n",
              "\t\tif (object.style.opacity>=1) return -1;\n",
              "\t//\tvar initialOpacity = 100;\n",
              "\t}\n",
              "\tvar i = 0;\n",
              "\tvar targetOpacity = 100;\n",
              "\tobject.style.visibility = \"visible\";\n",
              "\tif (object.style.opacity==\"\"||object.style.opacity==undefined) object.style.opacity=0;\n",
              "\tif (object.style.MozOpacity==\"\"||object.style.MozOpacity==undefined) object.style.MozOpacity=0;\n",
              "\tif (object.style.filter=\"\"||object.style.filter==undefined) object.style.filter = \"progid:DXImageTransform.Microsoft.Alpha(opacity=0)\";\n",
              "\tvar intervalID = setInterval(function() {\n",
              "\t\tobject.style.opacity = object.style.opacity * 1 + (targetOpacity/1000);\n",
              "\t\tobject.style.MozOpacity = object.style.MozOpacity * 1 + (targetOpacity/1000);\n",
              "\t\ti = i + (targetOpacity/10);\n",
              "\t\tvar buff = 'progid:DXImageTransform.Microsoft.Alpha(opacity=';\n",
              "\t\tbuff += i;\n",
              "\t\tbuff += ')';\n",
              "\t\tobject.style.filter = buff;\n",
              "\t\tif (i == targetOpacity) {\n",
              "\t\t\tclearInterval(intervalID);\n",
              "\t\t}\n",
              "\t}, mls / 10);\n",
              "};\n",
              "\n",
              "function fadeout (object,mls) {\n",
              "    if (object.style.opacity) {\n",
              "        if (object.style.opacity<=0) return -1;\n",
              "        var initialOpacity = 100;\n",
              "    }\n",
              "    else var initialOpacity = 100;\n",
              "    var i = initialOpacity;\n",
              "    if (object.style.opacity==\"\"||object.style.opacity==undefined) object.style.opacity=initialOpacity/100;\n",
              "    if (object.style.MozOpacity==\"\"||object.style.MozOpacity==undefined) object.style.MozOpacity=initialOpacity/100;\n",
              "    if (object.style.filter=\"\"||object.style.filter==undefined) object.style.filter = \"progid:DXImageTransform.Microsoft.Alpha(opacity=\"+initialOpacity+')';\n",
              "    var intervalID = setInterval(function() {\n",
              "\tobject.style.opacity = object.style.opacity * 1 - (initialOpacity/1000);\n",
              "\tobject.style.MozOpacity = object.style.MozOpacity * 1 - (initialOpacity/1000);\n",
              "\ti = i - (initialOpacity/10);\n",
              "\tvar buff = 'progid:DXImageTransform.Microsoft.Alpha(opacity=';\n",
              "\tbuff += i;\n",
              "\tbuff += ')';\n",
              "\tobject.style.filter = buff;\n",
              "\tif (i == 0) {\n",
              "\t    clearInterval(intervalID);\n",
              "\t}\n",
              "    }, mls / 10);\n",
              "    setTimeout(function() {\n",
              "        object.style.visibility = \"hidden\";\n",
              "    }, mls);\n",
              "}\n",
              "\n",
              "function showcut() {\n",
              "\tdocument.getElementById(\"cut\").style.display = \"block\";\n",
              "\tfadein(document.getElementById(\"cut\"),500);\n",
              "\tfadeout(document.getElementById(\"showcut\"),500);\n",
              "\tsetTimeout(function() {\n",
              "\t\tdocument.getElementById(\"showcut\").style.display = \"none\";\n",
              "\t\tdocument.getElementById(\"hidecut\").style.display = \"block\";\n",
              "\t\tfadein(document.getElementById(\"hidecut\"),500);\n",
              "\t\trsz();\n",
              "\t}, 500);\n",
              "}\n",
              "\n",
              "function hidecut() {\n",
              "\tfadeout(document.getElementById(\"cut\"),500);\n",
              "\tfadeout(document.getElementById(\"hidecut\"),500);\n",
              "\tsetTimeout(function() {\n",
              "\t\tdocument.getElementById(\"hidecut\").style.display = \"none\";\n",
              "\t\tdocument.getElementById(\"showcut\").style.display = \"block\";\n",
              "\t\tfadein(document.getElementById(\"showcut\"),500);\n",
              "\t\tdocument.getElementById(\"cut\").style.display = \"none\";\n",
              "\t\tdocument.documentElement.style.overflow=\"auto\";\n",
              "\t\tdocument.body.style.overflow=\"auto\";\n",
              "\t\trsz();\n",
              "\t}, 500);\n",
              "}\n",
              "\n",
              "function popupbox(event,id) {\n",
              "\tdocument.getElementById(id).style.display = \"block\";\n",
              "\tdocument.getElementById(id).style.left = event.pageX+\"px\";\n",
              "\tdocument.getElementById(id).style.top = document.getElementById(id+\"link\").getBoundingClientRect().bottom+pageYOffset+2+\"px\";\n",
              "\tfadein(document.getElementById(id),500);\n",
              "\tsetTimeout(function() {\n",
              "\t\tdocument.getElementById(id+\"link\").setAttribute(\"onclick\",\"hidebox('\"+id+\"')\");\n",
              "\t}, 500);\n",
              "}\n",
              "\n",
              "function hidebox(id) {\n",
              "\tfadeout(document.getElementById(id),500);\n",
              "\tsetTimeout(function() {\n",
              "\t\tdocument.getElementById(id).style.display = \"none\";\n",
              "\t\tdocument.getElementById(id+\"link\").setAttribute(\"onclick\",\"popupbox(event,'\"+id+\"')\");\n",
              "\t}, 500);\n",
              "}\n",
              "\n",
              "window.onload = function() {\n",
              "\n",
              "\tvar textarea = document.querySelector('textarea');\n",
              "\t\t     \n",
              "\tfunction autosize() {\n",
              "\t  var el = this;\n",
              "\t  setTimeout(function() {\n",
              "\t    el.style.cssText = 'height:auto; padding:0';\n",
              "\t    // for box-sizing other than \"content-box\" use:\n",
              "\t    // el.style.cssText = '-moz-box-sizing:content-box';\n",
              "\t    el.style.cssText = 'height:' + el.scrollHeight + 'px';\n",
              "\t  },0);\n",
              "\t}\n",
              "\t\n",
              "\trsz();\n",
              "\n",
              "\tfadein(document.body,500);\n",
              "};\n",
              "\n",
              "function showmasker(maskid) {\n",
              "\tvar placerShown = true;\n",
              "\tvar elements = document.getElementsByName('textmask');\n",
              "\tArray.prototype.forEach.call(elements, function(item){\n",
              "\t\tif (item.style.visibility==\"visible\") {\n",
              "\t\t\tfadeout(item,500);\n",
              "\t\t\tplacerShown = false;\n",
              "\t\t\tdocument.getElementById(item.id+'link').href=\"javascript:showmasker('\"+item.id+\"')\";\n",
              "\t\t}\n",
              "\t});\n",
              "\tfadein(document.getElementById(maskid),500);\n",
              "\tif (placerShown) fadeout(document.getElementById(\"textplacer\"),500);\n",
              "}\n",
              "\n",
              "function hidemasker(maskid) {\n",
              "\tfadeout(document.getElementById(maskid),500);\n",
              "\tfadein(document.getElementById(\"textplacer\"),500);\n",
              "}\n",
              "\n",
              "function reversemaskerlink(caller,maskid) {\n",
              "\tif (document.getElementById(maskid).style.opacity==1) caller.href=\"javascript:hidemasker('\"+maskid+\"')\";\n",
              "\telse caller.href=\"javascript:showmasker('\"+maskid+\"')\";\n",
              "}\n",
              "\n",
              "function rsz() {\n",
              "\tvar elements = document.getElementsByName('textmask');\n",
              "\tArray.prototype.forEach.call(elements, function(item){\n",
              "\titem.style.width = \"100%\";\n",
              "\t});\n",
              "\tvar elements = document.getElementsByName('popupbox');\n",
              "\tArray.prototype.forEach.call(elements, function(item){\n",
              "\tif (item.style.display!=\"none\") {\n",
              "\t\t\thidebox(item.id)\n",
              "\t\t}\n",
              "\t});\n",
              "\tsetTimeout(function() {\n",
              "\t\tvar allelems = document.getElementsByTagName('*');\n",
              "\t\tArray.prototype.forEach.call(allelems, function(item){\n",
              "\t\tif (item.style.opacity)\n",
              "\t\t\tif (item.style.opacity<0)\n",
              "\t\t\t\titem.style.opacity=0;\n",
              "\t\t});\n",
              "\t},1000);\n",
              "};\n",
              "\n",
              "var em=18;\n",
              "\n",
              "function getValue(id) {\n",
              "  var div = document.getElementById(id);\n",
              "  div.style.height = '1em';\n",
              "  var e = div.offsetHeight;\n",
              "  div.style.height = '0px';\n",
              "  return ( em =  e );\n",
              "}\n",
              "\n",
              "window.onload = function() {\n",
              " getValue(\"div\");\n",
              "}\n",
              "\n",
              "function _getrect(bcr, crs, mY) {\n",
              "  if (Math.round(bcr.height) == Math.round(crs[0].height)) {\n",
              "    return bcr;\n",
              "  }\n",
              "  if (mY > bcr.top + bcr.height / 2) {\n",
              "    return crs[crs.length - 1];\n",
              "  }\n",
              "  return crs[0];\n",
              "}\n",
              "\n",
              "function showhide(caller) {\n",
              "  var del = caller.parentElement.firstChild;\n",
              "  del.classList.toggle('hidden'); \n",
              "  var hider = del.nextSibling;\n",
              "  if (hider != caller || caller.classList.contains(\"error-hider\")) {\n",
              "\thider.classList.toggle('hidden');\n",
              "  }\n",
              "};\n",
              "\n",
              "function showcomment(caller, event) {\n",
              "  var elemtitle = caller.lastChild;\n",
              "  elemtitle.style.visibility = 'visible';\n",
              "  var rect = _getrect(caller.getBoundingClientRect(), caller.getClientRects(), event.clientY);\n",
              "  var prect = caller.parentNode.getBoundingClientRect();\n",
              "  var crect = elemtitle.getBoundingClientRect();\n",
              "  var varleft = rect.left + rect.width / 2 - crect.width / 2;\n",
              "  var oldleft = varleft;\n",
              "  if (varleft < prect.left) {\n",
              "    varleft = prect.left;\n",
              "  }\n",
              "  if (varleft + crect.width > prect.right) {\n",
              "    varleft = prect.right - crect.width;\n",
              "  }\n",
              "  elemtitle.style.top = (rect.top - prect.top) + 6 + 'px';\n",
              "  elemtitle.style.left = varleft + 'px';\n",
              "  var arrowleft = crect.width / 2 - 0.375 / 2 * em;\n",
              "  if (oldleft != varleft) {\n",
              "    arrowleft = arrowleft + (oldleft - varleft)\n",
              "  }\n",
              "  elemtitle.style.setProperty('--left-pos', arrowleft + \"px\");\n",
              "};\n",
              "\n",
              "function hidecomment(caller) {\n",
              "  var elemtitle = caller.lastChild;\n",
              "  elemtitle.style.visibility = 'hidden';\n",
              "};\n",
              "\n",
              "function copyDivToClipboard() {\n",
              "\tvar Div = document.getElementById(\"resulta\").cloneNode(true);\n",
              "\tArray.prototype.slice.call(Div.getElementsByTagName('del')).forEach(\n",
              "\t  function(item) {\n",
              "\t\titem.remove();\n",
              "\t\t// or item.parentNode.removeChild(item); for older browsers (Edge-)\n",
              "\t});\n",
              "\tArray.prototype.slice.call(Div.getElementsByTagName('hgroup')).forEach(\n",
              "\t  function(item) {\n",
              "\t\titem.remove();\n",
              "\t\t// or item.parentNode.removeChild(item); for older browsers (Edge-)\n",
              "\t});\n",
              "\tArray.prototype.slice.call(Div.getElementsByClassName('error-hider')).forEach(\n",
              "\t  function(item) {\n",
              "\t\titem.remove();\n",
              "\t\t// or item.parentNode.removeChild(item); for older browsers (Edge-)\n",
              "\t});\n",
              "\tDiv.id = \"shadowa\";\n",
              "\tdocument.body.appendChild(Div);\n",
              "\tvar range = document.createRange(div);\n",
              "\t// range.selectNode(Div);\n",
              "\trange.selectNode(document.getElementById(\"shadowa\"));\n",
              "\twindow.getSelection().removeAllRanges(); // clear current selection\n",
              "\twindow.getSelection().addRange(range); // to select text\n",
              "\tdocument.execCommand(\"copy\");\n",
              "\twindow.getSelection().removeAllRanges();// to deselect\n",
              "\tDiv.remove();\n",
              "}\n",
              "\n",
              "function loadOut() {\n",
              "\t$(\"html\").addClass(\"loadout\");\n",
              "\tsetTimeout( function() {\n",
              "\t\t$(\"html\")[0].style.display = \"none\";\n",
              "\t}, 1000);\n",
              "}\n",
              "</script>\n",
              "</head>\n",
              "<body>\n",
              "<div class=\"header2\">\n",
              "\t\t\t\tYour corrected text:\n",
              "\t\t\t\t</div><br>\n",
              "<div id=\"resulta\" style=\"\"><span>In </span><div style=\"display: inline;\" onmouseover=\"showcomment(this, event);\" onmouseleave=\"hidecomment(this);\"><ins class=\"gram\">the </ins><hgroup class=\"gram error-type\" style=\"left: 709.15px; visibility: hidden; top: 70.5px; --left-pos:NaNpx;\"><span>Word-level grammar error</span></hgroup></div><span>modern world our life is demanding more and more different knowledge and skills from us so to set it</span><div style=\"display: inline;\" onmouseover=\"showcomment(this, event);\" onmouseleave=\"hidecomment(this);\"><ins class=\"punct\">,</ins><hgroup class=\"punct error-type\" style=\"left: 709.15px; visibility: hidden; top: 70.5px; --left-pos:NaNpx;\"><span>Punctuation error</span></hgroup></div><span> children from </span><div style=\"display: inline;\" onmouseover=\"showcomment(this, event);\" onmouseleave=\"hidecomment(this);\"><ins class=\"gram\">an </ins><hgroup class=\"gram error-type\" style=\"left: 709.15px; visibility: hidden; top: 70.5px; --left-pos:NaNpx;\"><span>Word-level grammar error</span></hgroup></div><span>early age go to some lessons and courses. Because of </span><div style=\"display: inline;\" onmouseover=\"showcomment(this, event);\" onmouseleave=\"hidecomment(this);\"><del class=\"hidden punct\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">it </del><div class=\"punct error-hider\" onclick=\"showhide(this);\"></div><ins class=\"punct\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">this, </ins><hgroup class=\"punct error-type\" style=\"left: 709.15px; visibility: hidden; top: 70.5px; --left-pos:NaNpx;\"><span>Punctuation error</span></hgroup></div><span>they usually spend quite a little time outside and </span><div style=\"display: inline;\" onmouseover=\"showcomment(this, event);\" onmouseleave=\"hidecomment(this);\"><del class=\"hidden gram\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">do</del><div class=\"gram error-hider\" onclick=\"showhide(this);\"></div><ins class=\"gram\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">are</ins><hgroup class=\"gram error-type\" style=\"left: 709.15px; visibility: hidden; top: 70.5px; --left-pos:NaNpx;\"><span>Word-level grammar error</span></hgroup></div><span> not aware of all </span><div style=\"display: inline;\" onmouseover=\"showcomment(this, event);\" onmouseleave=\"hidecomment(this);\"><ins class=\"gram\">the </ins><hgroup class=\"gram error-type\" style=\"left: 709.15px; visibility: hidden; top: 70.5px; --left-pos:NaNpx;\"><span>Word-level grammar error</span></hgroup></div><span>value and beauty of our nature</span><div style=\"display: inline;\" onmouseover=\"showcomment(this, event);\" onmouseleave=\"hidecomment(this);\"><del class=\"hidden punct\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">,</del><div class=\"punct error-hider\" onclick=\"showhide(this);\"></div><ins class=\"punct\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">.</ins><hgroup class=\"punct error-type\" style=\"left: 709.15px; visibility: hidden; top: 70.5px; --left-pos:NaNpx;\"><span>Punctuation error</span></hgroup></div><span> I can partly </span><div style=\"display: inline;\" onmouseover=\"showcomment(this, event);\" onmouseleave=\"hidecomment(this);\"><del class=\"hidden spell\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">asree</del><div class=\"spell error-hider\" onclick=\"showhide(this);\"></div><ins class=\"spell\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">agree</ins><hgroup class=\"spell error-type\" style=\"left: 709.15px; visibility: hidden; top: 70.5px; --left-pos:NaNpx;\"><span>Spelling error</span></hgroup></div><span> with this statement.<br></span><div style=\"display: inline;\" onmouseover=\"showcomment(this, event);\" onmouseleave=\"hidecomment(this);\"><del class=\"hidden gram\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">From </del><div class=\"gram error-hider\" onclick=\"showhide(this);\"></div><ins class=\"gram\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">On the </ins><hgroup class=\"gram error-type\" style=\"left: 709.15px; visibility: hidden; top: 70.5px; --left-pos:NaNpx;\"><span>Word-level grammar error</span></hgroup></div><span>one </span><div style=\"display: inline;\" onmouseover=\"showcomment(this, event);\" onmouseleave=\"hidecomment(this);\"><del class=\"hidden vocab\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">side</del><div class=\"vocab error-hider\" onclick=\"showhide(this);\"></div><ins class=\"vocab\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">hand</ins><hgroup class=\"vocab error-type\" style=\"left: 709.15px; visibility: hidden; top: 70.5px; --left-pos:NaNpx;\"><span>Vocabulary error</span></hgroup></div><span>, it is true that </span><div style=\"display: inline;\" onmouseover=\"showcomment(this, event);\" onmouseleave=\"hidecomment(this);\"><del class=\"hidden spell\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">nowdays</del><div class=\"spell error-hider\" onclick=\"showhide(this);\"></div><ins class=\"spell\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">nowadays</ins><hgroup class=\"spell error-type\" style=\"left: 709.15px; visibility: hidden; top: 70.5px; --left-pos:NaNpx;\"><span>Spelling error</span></hgroup></div><span> children </span><div style=\"display: inline;\" onmouseover=\"showcomment(this, event);\" onmouseleave=\"hidecomment(this);\"><del class=\"hidden gram\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">spent</del><div class=\"gram error-hider\" onclick=\"showhide(this);\"></div><ins class=\"gram\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">spend</ins><hgroup class=\"gram error-type\" style=\"left: 709.15px; visibility: hidden; top: 70.5px; --left-pos:NaNpx;\"><span>Word-level grammar error</span></hgroup></div><span> less time outside enjoying some simple things such as trees, grass, </span><div style=\"display: inline;\" onmouseover=\"showcomment(this, event);\" onmouseleave=\"hidecomment(this);\"><ins class=\"gram\">the </ins><hgroup class=\"gram error-type\" style=\"left: 709.15px; visibility: hidden; top: 70.5px; --left-pos:NaNpx;\"><span>Word-level grammar error</span></hgroup></div><span>sun and fresh air. Even when they go for a walk, in big </span><div style=\"display: inline;\" onmouseover=\"showcomment(this, event);\" onmouseleave=\"hidecomment(this);\"><del class=\"hidden spell\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">sities</del><div class=\"spell error-hider\" onclick=\"showhide(this);\"></div><ins class=\"spell\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">cities</ins><hgroup class=\"spell error-type\" style=\"left: 709.15px; visibility: hidden; top: 70.5px; --left-pos:NaNpx;\"><span>Spelling error</span></hgroup></div><span> it is complicated to find </span><div style=\"display: inline;\" onmouseover=\"showcomment(this, event);\" onmouseleave=\"hidecomment(this);\"><ins class=\"gram\">a </ins><hgroup class=\"gram error-type\" style=\"left: 709.15px; visibility: hidden; top: 70.5px; --left-pos:NaNpx;\"><span>Word-level grammar error</span></hgroup></div><span>place where virgin nature is saved. They have to walk around blocks of flats and roads where no fresh air or spectacular views are left, although they are very important.<br></span><div style=\"display: inline;\" onmouseover=\"showcomment(this, event);\" onmouseleave=\"hidecomment(this);\"><del class=\"hidden gram\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">From </del><div class=\"gram error-hider\" onclick=\"showhide(this);\"></div><ins class=\"gram\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">On the </ins><hgroup class=\"gram error-type\" style=\"left: 709.15px; visibility: hidden; top: 70.5px; --left-pos:NaNpx;\"><span>Word-level grammar error</span></hgroup></div><span>other </span><div style=\"display: inline;\" onmouseover=\"showcomment(this, event);\" onmouseleave=\"hidecomment(this);\"><del class=\"hidden vocab\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">side</del><div class=\"vocab error-hider\" onclick=\"showhide(this);\"></div><ins class=\"vocab\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">hand</ins><hgroup class=\"vocab error-type\" style=\"left: 709.15px; visibility: hidden; top: 70.5px; --left-pos:NaNpx;\"><span>Vocabulary error</span></hgroup></div><span>, there is a lot of time children have to spend learning </span><div style=\"display: inline;\" onmouseover=\"showcomment(this, event);\" onmouseleave=\"hidecomment(this);\"><ins class=\"gram\">about </ins><hgroup class=\"gram error-type\" style=\"left: 709.15px; visibility: hidden; top: 70.5px; --left-pos:NaNpx;\"><span>Word-level grammar error</span></hgroup></div><span>nature. They all have holidays when parents try to send </span><div style=\"display: inline;\" onmouseover=\"showcomment(this, event);\" onmouseleave=\"hidecomment(this);\"><del class=\"hidden gram\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">they</del><div class=\"gram error-hider\" onclick=\"showhide(this);\"></div><ins class=\"gram\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">them</ins><hgroup class=\"gram error-type\" style=\"left: 709.15px; visibility: hidden; top: 70.5px; --left-pos:NaNpx;\"><span>Word-level grammar error</span></hgroup></div><span> to different camps in forests or </span><div style=\"display: inline;\" onmouseover=\"showcomment(this, event);\" onmouseleave=\"hidecomment(this);\"><del class=\"hidden gram\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">round</del><div class=\"gram error-hider\" onclick=\"showhide(this);\"></div><ins class=\"gram\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">around</ins><hgroup class=\"gram error-type\" style=\"left: 709.15px; visibility: hidden; top: 70.5px; --left-pos:NaNpx;\"><span>Word-level grammar error</span></hgroup></div><span> the sea, to countryside where a lot of them have relatives or friends and so on.<br>So</span><div style=\"display: inline;\" onmouseover=\"showcomment(this, event);\" onmouseleave=\"hidecomment(this);\"><del class=\"hidden gram\" style=\"cursor: pointer;\" onclick=\"showhide(this);\"> in</del><div class=\"gram error-hider\" onclick=\"showhide(this);\"></div><ins class=\"gram\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">, at</ins><hgroup class=\"gram error-type\" style=\"left: 709.15px; visibility: hidden; top: 70.5px; --left-pos:NaNpx;\"><span>Word-level grammar error</span></hgroup></div><span> this time</span><div style=\"display: inline;\" onmouseover=\"showcomment(this, event);\" onmouseleave=\"hidecomment(this);\"><ins class=\"punct\">,</ins><hgroup class=\"punct error-type\" style=\"left: 709.15px; visibility: hidden; top: 70.5px; --left-pos:NaNpx;\"><span>Punctuation error</span></hgroup></div><span> children have enough space and hours to learn more about nature, to learn to understand and appreciate it, to see how </span><div style=\"display: inline;\" onmouseover=\"showcomment(this, event);\" onmouseleave=\"hidecomment(this);\"><del class=\"hidden gram\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">many</del><div class=\"gram error-hider\" onclick=\"showhide(this);\"></div><ins class=\"gram\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">much</ins><hgroup class=\"gram error-type\" style=\"left: 709.15px; visibility: hidden; top: 70.5px; --left-pos:NaNpx;\"><span>Word-level grammar error</span></hgroup></div><span> it can give us and enjoy all of its advantages.<br>To sum up, it is harder for children to spend a lot of time outside learning </span><div style=\"display: inline;\" onmouseover=\"showcomment(this, event);\" onmouseleave=\"hidecomment(this);\"><del class=\"hidden gram\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">the</del><div class=\"gram error-hider\" onclick=\"showhide(this);\"></div><ins class=\"gram\" style=\"cursor: pointer;\" onclick=\"showhide(this);\">about</ins><hgroup class=\"gram error-type\" style=\"left: 709.15px; visibility: hidden; top: 70.5px; --left-pos:NaNpx;\"><span>Word-level grammar error</span></hgroup></div><span> nature now than it was before because of </span><div style=\"display: inline;\" onmouseover=\"showcomment(this, event);\" onmouseleave=\"hidecomment(this);\"><ins class=\"gram\">the </ins><hgroup class=\"gram error-type\" style=\"left: 709.15px; visibility: hidden; top: 70.5px; --left-pos:NaNpx;\"><span>Word-level grammar error</span></hgroup></div><span>crazy life rhythm but there are quite a lot of possibilities to do it if they want.</span></div>\n",
              "\n",
              "</body></html>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3c_74rjoxAP"
      },
      "source": [
        "## Download the results\n",
        "\n",
        "Now, you may also want to get the texts processed by `heptabot`. The code below downloads the texts directly to your computer: unzip it to view the results as they would be displayed in the web version. With Colab, you can also easily save the resulting folder to your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H22D7MHZowmf"
      },
      "source": [
        "!zip -q heptabot_processed.zip -r output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7XuyUELVy-t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6aefbd26-7e21-4cb7-82ed-42e2f75369b1"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"heptabot_processed.zip\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a1989da2-808c-4565-8a36-b766a990b153\", \"heptabot_processed.zip\", 82623)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH35ksIc5qj6"
      },
      "source": [
        "## Measure performance\n",
        "\n",
        "Finally, here we include a section to test the performance of this version and reproduce the scores we report for some Grammar Error Correction tasks. Our test set for `correction` task consists of 40 texts, 20 with 1000 symbols and 30 with 1500 symbols (texts of such length are fairly common in [REALEC](https://realec.org/)), for the total of 50000 symbols. During our research, we found out that using GLEU to assess the performance of `correction` is not very informative, so we do not measure the quality of our model for this task.\n",
        "\n",
        "**Important:** please note that in order to reproduce our BEA-2019 score you need to upload the zipped version of our `bea` task output, which will automatically start downloading near the end of this cell's execution, to the official [scoring system](https://competitions.codalab.org/competitions/20229#participate)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "id": "3yiNUUAt5tV0",
        "outputId": "9f5c0543-034b-41f8-94f4-aecc7dee157c"
      },
      "source": [
        "!chmod +x run_measures.sh\n",
        "!bash run_measures.sh\n",
        "download(\"bea_test_heptabot_{}_{}.zip\".format(os.environ[\"HPT_MODEL_TYPE\"], os.environ[\"MODEL_PLACE\"]))\n",
        "print(\"All tests finished.\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating heptabot \"medium\" model on architecture \"tpu\"\n",
            "\n",
            "Test 1. Correction task, running time and memory usage\n",
            "Preparing texts for TPU model inference\n",
            "100% 40/40 [00:00<00:00, 273.55it/s]\n",
            "Processing TPU model outputs\n",
            "100% 40/40 [00:32<00:00,  1.22it/s]\n",
            "RAM used: 2.193 GiB\n",
            "Time elapsed: 1 minutes 23 seconds\n",
            "Average time/text: 2.075 secs\n",
            "Average time/symbol: 1.66 ms\n",
            "Note that for TPU RAM usage is not so relevant and elapsed time included system startup unlike in CPU and GPU tests.\n",
            "\n",
            "Test 2. Competition scores\n",
            "Getting JFLEG from https://github.com/keisks/jfleg\n",
            "Getting CONLL-14 test set from https://www.comp.nus.edu.sg/~nlp/conll14st/conll14st-test-data.tar.gz, M2-scorer from https://www.comp.nus.edu.sg/~nlp/sw/m2scorer.tar.gz\n",
            "Getting BEA-2019 test set from https://www.cl.cam.ac.uk/research/nl/bea2019st/data/ABCN.test.bea19.orig\n",
            "Preparing input for heptabot...\n",
            "Processing files...\n",
            "Preparing texts for TPU model inference\n",
            "100% 3/3 [00:11<00:00,  3.75s/it]\n",
            "Processing TPU model outputs\n",
            "100% 3/3 [00:00<00:00,  9.52it/s]\n",
            "All files processed.\n",
            "\n",
            "** Testing on CoNLL-2014. See official scorer output below **\n",
            "Precision   : 0.7022\n",
            "Recall      : 0.4609\n",
            "F_0.5       : 0.6356\n",
            "\n",
            "** Testing on JFLEG. See official scorer output below **\n",
            "Running GLEU...\n",
            "../jfleg.res\n",
            "[['0.605325', '0.007913', '(0.590,0.621)']]\n",
            "\n",
            "** To get BEA scores, please upload our output to the official scoring system. **\n",
            "** The system is located at https://competitions.codalab.org/competitions/20229#participate. **\n",
            "** Our generated output will start downloading shortly. **\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_242240fc-d22d-4db1-83f3-32bb82b2539c\", \"bea_test_heptabot_medium_tpu.zip\", 159780)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "All tests finished.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}