{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCpdqIxO9XlR"
   },
   "source": [
    "# Run heptabot `tiny` model from Docker image\n",
    "\n",
    "This notebook showcases a way to process data with `heptabot` using JupyterLab in your container image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3RnugVBrx8h"
   },
   "source": [
    "First, let's initialize the system. Note that in the process of creating the image this notebook gets moved to the root `heptabot` directory, so we assume we're already there, not in `heptabot/notebooks`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AsC233uxusk9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pickle\n",
    "import Pyro4\n",
    "import Pyro4.util\n",
    "from time import sleep\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "!mkdir input\n",
    "!mkdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9GRWK96trx8i",
    "outputId": "a6dda8ef-5f33-4641-e4db-7e599ebbaf05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing prompt_run.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile prompt_run.sh\n",
    "source ~/mambaforge/etc/profile.d/conda.sh\n",
    "export MODEL_PLACE=cpu\n",
    "conda activate heptabot\n",
    "pyro4-ns &\n",
    "sleep 5; python models.py &\n",
    "sleep 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "i-65jplkvGVb",
    "outputId": "54ad523b-0f24-48c9-81a3-5dd9d0cf2be8"
   },
   "outputs": [],
   "source": [
    "os.environ[\"HPT_MODEL_TYPE\"] = \"tiny\"\n",
    "!chmod +x prompt_run.sh\n",
    "subprocess.Popen([\"/bin/bash\", os.path.join(os.path.abspath(os.getcwd()), \"prompt_run.sh\")])\n",
    "sleep(70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jICv-V0erx8m"
   },
   "source": [
    "After waiting around 70 seconds, the model should be up and running, so we connect to it using `Pyro4`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6rBOA0Esrx8m"
   },
   "outputs": [],
   "source": [
    "Heptamodel = Pyro4.Proxy(\"PYRONAME:heptabot.heptamodel\")\n",
    "batchify, process_batch, result_to_div = Heptamodel.batchify, Heptamodel.process_batch, Heptamodel.result_to_div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6vHykMyrx8m"
   },
   "source": [
    "Now let's get some example texts, each having 300 words, as measured by `nltk.word_tokenize`, and perform correction. You will find the correction results in `output` directory. Feel free to change the cell below to process the texts you need.\n",
    "\n",
    "**Important**: please choose the appropriate task type in the following cell. While `correction`, the default, is used to correct whole essays and only its pipeline incorporates the error classification subroutine, you may also want to perform sentencewise correction. In this case, choose one of the identifiers of the relevant GEC tasks: `jfleg` (trained on JFLEG data) is for general sentencewise correction and should provide more diverse results, while `conll` (trained on CONLL-14 competition) and `bea` (trained on BEA-2019 competition) correct mainly grammar-related errors, for which case the grammar parsing data is appended to the sentence in the corresponding pipeline. Please note that `heptabot` expects whole paragraphs of text as data for `correction` and sentence-by-sentence structured data for other tasks, so make sure your file(s) contain single sentences separated by newlines if you wish to perform any other task than `correction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "diRK7ug_rx8m"
   },
   "outputs": [],
   "source": [
    "!wget -q \"https://realec.org/ajax.cgi?action=downloadFile&collection=%2Fexam%2FExam2015%2F&document=2015_KT_12_2&extension=txt&protocol=1\" -O ./input/KT_12_2.txt\n",
    "!wget -q \"https://realec.org/ajax.cgi?action=downloadFile&collection=%2Fexam%2FExam2014%2F&document=2014_ESha_2_1&extension=txt&protocol=1\" -O ./input/ESha_2_1.txt\n",
    "!wget -q \"https://realec.org/ajax.cgi?action=downloadFile&collection=%2Fexam%2FExam2016%2F&document=2016_LKa_2_2&extension=txt&protocol=1\" -O ./input/LKa_2_2.txt\n",
    "\n",
    "files = [\"KT_12_2.txt\", \"ESha_2_1.txt\", \"LKa_2_2.txt\"]\n",
    "textdict = {}\n",
    "\n",
    "for f in files:\n",
    "  with open(os.path.join(\"input\", f), \"r\", encoding=\"utf-8\") as infile:\n",
    "    textdict[f[:-4]] = infile.read()\n",
    "\n",
    "task_type = \"correction\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFHKBWsstUdK"
   },
   "source": [
    "Now we will convert the initial collection in `textdict` to the final `texts` dict which we will then pass to the model. Note that you may set different type of task for each text: tasks in one batch don't have to be uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8rC-6GS3tUDm"
   },
   "outputs": [],
   "source": [
    "texts = {}\n",
    "\n",
    "for textid in textdict:\n",
    "  texts[textid] = {\"task_type\": task_type, \"text\": textdict[textid]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Rksp8s2rx8n"
   },
   "source": [
    "And now it is time to actually perform the correction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ltEZaImbrx8n",
    "outputId": "d1117b39-3cfe-4ba6-b9fa-6aa599e16e1d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa18173ae43644a09b7af3367cd69636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 63 ms, sys: 6.33 ms, total: 69.3 ms\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prepared_data = {}\n",
    "for textid in texts:\n",
    "    batches, delims = batchify(texts[textid][\"text\"], texts[textid][\"task_type\"])    \n",
    "    prepared_data[textid] = (texts[textid][\"task_type\"], batches, delims)\n",
    "\n",
    "with open(\"./templates/result.html\", \"r\") as inres:\n",
    "    outhtml = inres.read()\n",
    "outhtml = outhtml.replace(\"{{ which_font }}\", \"{0}\").replace(\"{{ response }}\", \"{1}\").replace(\"{{ task_type }}\", \"{2}\")\n",
    "\n",
    "for textid in tqdm(prepared_data):\n",
    "    task_type, batches, delims = prepared_data[textid]\n",
    "    which_font = \"\" if task_type == \"correction\" else \"font-family: Ubuntu Mono; letter-spacing: -0.5px;\"\n",
    "    task_str = \"text\" if task_type == \"correction\" else \"sentences\"\n",
    "    processed = []\n",
    "\n",
    "    if task_type != \"correction\":\n",
    "        print(\"Processing text with ID\", textid)\n",
    "        for batch in tqdm(batches):\n",
    "            processed.append(process_batch(batch))\n",
    "    else:\n",
    "        for batch in batches:\n",
    "            processed.append(process_batch(batch))\n",
    "    response = result_to_div(texts[textid][\"text\"], processed, delims, task_type)\n",
    "\n",
    "    proc_html = outhtml.format(which_font, response, task_str)\n",
    "    with open(os.path.join(\"output\", textid + \".html\"), \"w\", encoding=\"utf-8\") as outfile:\n",
    "        outfile.write(proc_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3c_74rjoxAP"
   },
   "source": [
    "## Download the results\n",
    "\n",
    "Here you may also want to get the texts processed by `heptabot`. The code below creates an archive with all the processed files: download it from the menu on the left and unzip on your device to view the results as they would be displayed in the Web version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "H22D7MHZowmf"
   },
   "outputs": [],
   "source": [
    "!zip -q heptabot_processed.zip -r output"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Run_tiny_model_from_Docker_image.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
